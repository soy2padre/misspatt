
@article{Bacik1998,
  title = {Drug Use Prevention Data, Missed Assessments and Survival Analysis.},
  author = {Bacik, Jennifer M and Murphy, Susan A and Anthony, James C},
  year = {1998},
  volume = {33},
  pages = {573--588},
  publisher = {{Lawrence Erlbaum}},
  address = {{US}},
  issn = {0027-3171},
  abstract = {In prevention studies, researchers often investigate the incidence of initial drug experimentation or other drug use milestones and its relationship to individual attributes such as the level of parental monitoring or rebelliousness. In this case, survival analysis is the methodology of choice. Survival analysis methods deal efficiently with data from individuals who leave the study prematurely and do not return. However often individuals do return to the study. The application of survival analysis to a situation in which individuals miss assessments and later return is nonstandard. The authors begin with an illustration of how intermittent missed assessments combined with prototypical questions lead to knowledge of the initiation times only up to a range of time intervals. Next, 2 missing data procedures, artificial censoring and multiple imputation, for dealing with the imprecision in timing caused by intermittent missed assessments are discussed. In the last section, both missing data procedures are applied to each of 2 sets of data collected from a 6-yr epidemiological study of children. Data from a subset of 694 girls was used. To compare the 2 procedures the authors compare the results of subsequent use of discrete time survival analysis. (PsycINFO Database Record (c) 2012 APA, all rights reserved)},
  journal = {Multivariate Behavioral Research},
  keywords = {6 yr study,discrete time survival analysis \& artificial censo,Experimentation,girls,Human Females DI - 10.1207/s15327906mbr3304_6,Measurement,Statistical Analysis},
  number = {4},
  series = {Innovative Methods for Prevention Research}
}

@article{Bernaards1999,
  title = {Factor Analysis of Multidimensional Polytomous Item Response Data Suffering from Ignorable Item Nonresponse.},
  author = {Bernaards, Coen A and Sijtsma, Klaas},
  year = {1999},
  volume = {34},
  pages = {277--313},
  publisher = {{Lawrence Erlbaum}},
  address = {{US}},
  issn = {0027-3171},
  abstract = {Investigated the problem of missing item responses in tests and questionnaires when using factor analysis to study the structure of the items. Multidimensional rating scale data were simulated, and item scores were deleted under D. B. Rubin"s (1976) MAR and MCAR definitions. Five imputation methods, the EM algorithm, and listwise deletion were implemented to deal with the item score missingness. Factor analysis was done on the complete data matrix, and on the seven data matrices that resulted from the application of each of the missingness methods. The factor loadings structure based on EM best approximated the loadings structure obtained from the complete data. Imputation of the mean per person across the available scores for that person was the best alternative to EM . It is recommended to researchers to use this simple method when EM is not available or when expertise to implement EM is lacking. (PsycINFO Database Record (c) 2012 APA, all rights reserved)},
  journal = {Multivariate Behavioral Research},
  keywords = {Algorithms,Factor Analysis,factor analysis of complete data vs data containin,Item Analysis (Statistical),Item Analysis (Test),Scoring (Testing) DI - 10.1207/S15327906MBR3403_1,Test Items,Test Scores},
  number = {3}
}

@article{Blozis2013,
  title = {Sensitivity Analysis of Multiple Informant Models When Data Are Not Missing at {{Random}}.},
  author = {Blozis, Shelley A and Ge, Xiaojia and Xu, Shu and Natsuaki, Misaki N and Shaw, Daniel S and Neiderhiser, Jenae M and Scaramella, Laura V and Leve, Leslie D and Reiss, David},
  year = {2013},
  month = apr,
  volume = {20},
  pages = {283--298},
  publisher = {{Taylor \& Francis}},
  address = {{Blozis, Shelley A., Department of Psychology, University of California, Davis, One Shields Avenue, Davis, CA, US, 95616}},
  issn = {1070-5511},
  abstract = {Missing data are common in studies that rely on multiple informant data to evaluate relationships among variables for distinguishable individuals clustered within groups. Estimation of structural equation models using raw data allows for incomplete data, and so all groups can be retained for analysis even if only 1 member of a group contributes data. Statistical inference is based on the assumption that data are missing completely at random or missing at random. Importantly, whether or not data are missing is assumed to be independent of the missing data. A saturated correlates model that incorporates correlates of the missingness or the missing data into an analysis and multiple imputation that might also use such correlates offer advantages over the standard implementation of SEM when data are not missing at random because these approaches could result in a data analysis problem for which the missingness is ignorable. This article considers these approaches in an analysis of family data to assess the sensitivity of parameter estimates and statistical inferences to assumptions about missing data, a strategy that could be easily implemented using SEM software. (PsycINFO Database Record (c) 2013 APA, all rights reserved). (journal abstract)},
  journal = {Structural Equation Modeling},
  keywords = {missing data,multiple informants,parameter estimates,Response Parameters,sensitivity analysis,Statistical Data,statistical inferences,Structural Equation Modeling,structural equation models},
  number = {2}
}

@article{Bodner2008,
  title = {What Improves with Increased Missing Data Imputations?},
  author = {Bodner, Todd E},
  year = {2008},
  month = oct,
  volume = {15},
  pages = {651--675},
  publisher = {{Taylor \& Francis}},
  address = {{Bodner, Todd E., Department of Psychology, Portland State University, P.O. Box 751, Portland, OR, US, 97207}},
  issn = {1070-5511},
  abstract = {When using multiple imputation in the analysis of incomplete data, a prominent guideline suggests that more than 10 imputed data values are seldom needed. This article calls into question the optimism of this guideline and illustrates that important quantities (e.g., p values, confidence interval half-widths, and estimated fractions of missing information) suffer from substantial imprecision with a small number of imputations. Substantively, a researcher can draw categorically different conclusions about null hypothesis rejection, estimation precision, and missing information in distinct multiple imputation runs for the same data and analysis with few imputations. This article explores the factors associated with this imprecision, demonstrates that precision improves by increasing the number of imputations, and provides practical guidelines for choosing a reasonable number of imputations to reduce imprecision for each of these quantities. (PsycINFO Database Record (c) 2012 APA, all rights reserved). (journal abstract)},
  journal = {Structural Equation Modeling},
  keywords = {imprecision,missing data,multiple imputation,Null Hypothesis Testing,Statistical Data,Statistical Estimation DI - 10.1080/1070551080233},
  number = {4}
}

@article{Braeken2016,
  title = {An Empirical Kaiser Criterion an Empirical Kaiser Criterion},
  author = {Braeken, Johan and Assen, Marcel A L M Van and Braeken, Johan},
  year = {2016},
  volume = {21},
  pages = {1--17},
  keywords = {1960,1966,cattell,dimen-,exploratory factor analysis,in exploratory factor analysis,kaiser,kaiser criterion,most popular methods for,or,parallel analysis,sionality assessment such as,the,the current gold standard,the screeplot},
  number = {1}
}

@article{breiman_bagging_1996,
  title = {Bagging Predictors},
  author = {Breiman, Leo},
  year = {1996},
  month = aug,
  volume = {24},
  pages = {123--140},
  issn = {0885-6125, 1573-0565},
  doi = {10.1007/BF00058655},
  abstract = {Bagging predictors is a method for generating multiple versions of a predictor and using these to get an aggregated predictor. The aggregation averages over the versions when predicting a numerical outcome and does a plurality vote when predicting a class. The multiple versions are formed by making bootstrap replicates of the learning set and using these as new learning sets. Tests on real and simulated data sets using classification and regression trees and subset selection in linear regression show that bagging can give substantial gains in accuracy. The vital element is the instability of the prediction method. If perturbing the learning set can cause significant changes in the predictor constructed, then bagging can improve accuracy.},
  file = {/Users/tub00573/Zotero/storage/ZPGTE48A/Breiman - 1996 - Bagging predictors.pdf},
  journal = {Machine Learning},
  language = {en},
  number = {2}
}

@article{Cai2009,
  title = {Covariance Structure Model Fit Testing under Missing Data: {{An}} Application of the Supplemented {{EM}} Algorithm.},
  author = {Cai, Li and Lee, Taehun},
  year = {2009},
  month = mar,
  volume = {44},
  pages = {281--304},
  publisher = {{Taylor \& Francis}},
  address = {{Cai, Li, Graduate School of Education and Information Studies, University of California, Los Angeles, 2331 Moore Hall, Box 951521, Los Angeles, CA, US, 90095-1521}},
  issn = {0027-3171},
  abstract = {We apply the Supplemented EM algorithm (Meng \& Rubin, 1991) to address a chronic problem with the ``two-stage'' fitting of covariance structure models in the presence of ignorable missing data: the lack of an asymptotically chi-square distributed goodness-of-fit statistic. We show that the Supplemented EM algorithm provides a convenient computational procedure that leads to such a chi-square statistic, and we provide a SAS macro implementing this method. Our derivations are corroborated with results from a small simulation study. We also apply the proposed method to 2 empirical data sets: (a) confirmatory factor analysis of Mardia, Kent, \& Bibby's 1979 Open-book Closed-book data and (b) conditional latent curve modeling of adolescent aggressive behavior as discussed by Curran (1997). (PsycINFO Database Record (c) 2012 APA, all rights reserved). (journal abstract)},
  journal = {Multivariate Behavioral Research},
  keywords = {Algorithms,Analysis of Covariance,covariance structure models,Goodness of Fit,goodness of fit statistics,missing data,Simulation,statistical methods,Statistical Tests,Statistics,Structural Equation Modeling,Supplemented EM algorithm,testing,Testing},
  number = {2}
}

@article{Campbell2007,
  title = {Computation of Individual Latent Variable Scores from Data with Multiple Missingness Patterns.},
  author = {Campbell, D D and Rijsdijk, F V and Sham, P C},
  year = {2007},
  month = mar,
  volume = {37},
  pages = {408--22},
  issn = {0001-8244},
  doi = {10.1007/s10519-006-9123-2},
  abstract = {Latent variable models are used in biological and social sciences to investigate characteristics that are not directly measurable. The generation of individual scores of latent variables can simplify subsequent analyses. However, missing measurements in real data complicate the calculation of scores. Missing observations also result in different latent variable scores having different degrees of accuracy which should be taken into account in subsequent analyses. This manuscript presents a publicly available software tool that addresses both these problems, using as an example a dataset consisting of multiple ratings for ADHD symptomatology in children. The program computes latent variable scores with accompanying accuracy indices, under a 'user-specified' structural equation model, in data with missing data patterns. Since structural equation models encompass factor models, it can also be used for calculating factor scores. The program, documentation and a tutorial, containing worked examples and specimen input and output files, is available at http://statgen.iop.kcl.ac.uk/lsc .},
  journal = {Behavior genetics},
  keywords = {Attention Deficit Disorder with Hyperactivity,Attention Deficit Disorder with Hyperactivity: gen,Biometry,Child,Genetic,Genetic Variation,Humans,Models,Reproducibility of Results},
  number = {2},
  pmid = {17120140}
}

@book{Cattell1973,
  title = {Personality and Mood by Questionnaire.},
  author = {Cattell, Raymond B.},
  year = {1973},
  publisher = {{Jossey-Bass}},
  address = {{Oxford, England}},
  abstract = {Presents a synthesis of over 700 studies on the statistical, methodological, and theoretical aspects of assessing personality by questionnaire. Topics include evaluation of all the major personality inventories, methods for integrating questionnaire data and findings from observation and laboratory studies, the use of computers in analyzing personality data, new techniques for eliminating bias in tests, and requirements for the construction and scoring of personality measures. (42 p ref)}
}

@article{Chen2008,
  title = {Theory and Inference for Regression Models with Missing Responses and Covariates.},
  author = {Chen, Qingxia and Ibrahim, Joseph G and Chen, Ming-Hui and Senchaudhuri, Pralay},
  year = {2008},
  month = jul,
  volume = {99},
  pages = {1302--1331},
  publisher = {{Elsevier Science}},
  address = {{Ibrahim, Joseph G., Department of Biostatistics, University of North Carolina, McGavran-Greenberg Hall, Chapel Hill, NC, US, 27599}},
  issn = {0047-259X},
  abstract = {In this paper, we carry out an in-depth theoretical investigation for inference with missing response and covariate data for general regression models. We assume that the missing data are missing at random (MAR) or missing completely at random (MCAR) throughout. Previous theoretical investigations in the literature have focused only on missing covariates or missing responses, but not both. Here, we consider theoretical properties of the estimates under three different estimation settings: complete case (CC) analysis, a complete response (CR) analysis that involves an analysis of those subjects with only completely observed responses, and the all case (AC) analysis, which is an analysis based on all of the cases. Under each scenario, we derive general expressions for the likelihood and devise estimation schemes based on the EM algorithm. We carry out a theoretical investigation of the three estimation methods in the normal linear model and analytically characterize the loss of information for each method, as well as derive and compare the asymptotic variances for each method assuming the missing data are MAR or MCAR. In addition, a theoretical investigation of bias for the CC method is also carried out. A simulation study and real dataset are given to illustrate the methodology. (PsycINFO Database Record (c) 2012 APA, all rights reserved). (journal abstract)},
  journal = {Journal of Multivariate Analysis},
  keywords = {complete case analysis,Mathematics,missing responses,Multivariate Analysis,random sampling,Random Sampling,regression models,Simulation,Statistical Estimation,Statistical Regression},
  number = {6}
}

@article{Codd2014,
  title = {Nonlinear Random-Effects Mixture Models for Repeated Measures.},
  author = {Codd, Casey L and Cudeck, Robert},
  year = {2014},
  month = jan,
  volume = {79},
  pages = {60--83},
  publisher = {{Springer}},
  address = {{Codd, Casey L., Psychology Department, Ohio State University, 240D Lazenby Hall, Columbus, OH, US, 43210}},
  issn = {0033-3123},
  abstract = {A mixture model for repeated measures based on nonlinear functions with random effects is reviewed. The model can include individual schedules of measurement, data missing at random, nonlinear functions of the random effects, of covariates and of residuals. Individual group membership probabilities and individual random effects are obtained as empirical Bayes predictions. Although this is a complicated model that combines a mixture of populations, nonlinear regression, and hierarchical models, it is straightforward to estimate by maximum likelihood using SAS PROC NLMIXED. Many different models can be studied with this procedure. The model is more general than those that can be estimated with most special purpose computer programs currently available because the response function is essentially any form of nonlinear regression. Examples and sample code are included to illustrate the method. (PsycINFO Database Record (c) 2014 APA, all rights reserved). (journal abstract)},
  journal = {Psychometrika},
  keywords = {Mathematical Modeling,maximum likelihood,Maximum Likelihood,missing data,non-linear random-effects mixture models,nonlinear regression,repeated measurement,Repeated Measures,Statistical Data,Statistical Regression DI - 10.1007/s11336-013-93},
  number = {1}
}

@article{Collins2001,
  title = {A Comparison of Inclusive and Restrictive Strategies in Modern Missing Data Procedures.},
  author = {Collins, L M and Schafer, J L and Kam, C M},
  year = {2001},
  month = dec,
  volume = {6},
  pages = {330--51},
  issn = {1082-989X},
  doi = {<a href="http://dx.doi.org.libproxy.temple.edu/10.1037/1082-989X.6.4.330" target="_blank" id="linkhttp:dx.doi.org10.10371082-989X.6.4.330" title="http://dx.doi.org.libproxy.temple.edu/10.1037/1082-989X.6.4.330" data-title="http://dx.doi.org.libproxy.temple.edu/10.1037/1082-989X.6.4.330">http://dx.doi.org.libproxy.temple.edu/10.1037/1082-989X.6.4.330</a>},
  abstract = {Two classes of modern missing data procedures, maximum likelihood (ML) and multiple imputation (MI), tend to yield similar results when implemented in comparable ways. In either approach, it is possible to include auxiliary variables solely for the purpose of improving the missing data procedure. A simulation was presented to assess the potential costs and benefits of a restrictive strategy, which makes minimal use of auxiliary variables, versus an inclusive strategy, which makes liberal use of such variables. The simulation showed that the inclusive strategy is to be greatly preferred. With an inclusive strategy not only is there a reduced chance of inadvertently omitting an important cause of missingness, there is also the possibility of noticeable gains in terms of increased efficiency and reduced bias, with only minor costs. As implemented in currently available software, the ML approach tends to encourage the use of a restrictive strategy, whereas the MI approach makes it relatively simple to use an inclusive strategy.},
  journal = {Psychological methods},
  keywords = {Confidence Intervals,Data Collection,Data Collection: statistics \& numerical data,Experimental,Experimental: statistics \& numerical d,Humans,Likelihood Functions,Models,Psychological Tests,Psychological Tests: statistics \& numerical data,Psychology,Psychometrics,Statistical},
  language = {English},
  number = {4},
  pmid = {11778676}
}

@article{davey_correcting_2001,
  title = {Correcting for Selective Nonresponse in the National Longitudinal Survey of Youth Using Multiple Imputation},
  author = {Davey, Adam and Shanahan, Michael J. and Schafer, Joseph L.},
  year = {2001},
  volume = {36},
  pages = {500},
  issn = {0022166X},
  doi = {10.2307/3069628},
  file = {/Users/tub00573/Zotero/storage/D4F95J2I/Davey et al. - 2001 - Correcting for Selective Nonresponse in the Nation.pdf;/Users/tub00573/Zotero/storage/EBWY3VI6/Davey et al. - 2001 - Correcting for Selective Nonresponse in the Nation.pdf},
  journal = {The Journal of Human Resources},
  language = {en},
  number = {3}
}

@article{Davey2005,
  title = {Issues in Evaluating Model Fit with Missing Data.},
  author = {Davey, Adam and Savla, Jyoti and Luo, Zupei},
  year = {2005},
  volume = {12},
  pages = {578--597},
  publisher = {{Lawrence Erlbaum}},
  address = {{Davey, Adam, Polisher Research Institute, 1425 Horsham Road, North Wales, PA, US, 19454-1320}},
  issn = {1070-5511},
  abstract = {Effects of incomplete data on fit indexes remain relatively unexplored. We evaluate a wide set of fit indexes ({$\chi{}^2$}, root mean squared error of appproximation, Normed Fit Index [NFI], Tucker-Lewis Index, comparative fit index, gamma-hat, and McDonald's Centrality Index) varying conditions of sample size (100-1,000 in increments of 50), factor loadings (.4 or .8), factor covariances (.4 or .8), type of missing data (missing completely at random or missing at random), and extent of missing data (0-95 \% on 3 of 9 indicators in increments of 5\%) for correct and 2 misspecified (measurement or structural) models. Incremental and absolute fit indexes indicate better fit with higher proportions of missing data. Effects of missing data on the NFI were more varied, indicating poorer model fit as missing data increased for the correct model, and indicating better or poorer fit as an interaction of all the other factors for misspecified models. Recommendations are made for researchers and software developers. (PsycINFO Database Record (c) 2012 APA, all rights reserved). (journal abstract)},
  journal = {Structural Equation Modeling},
  keywords = {factor covariances,factor loadings,fit indexes,Goodness of Fit,missing data,models,Models,Population (Statistics),sample size,Sample Size,Statistical Data,Variability Measurement DI - 10.1207/s15328007sem},
  number = {4}
}

@book{Davey2010,
  ids = {davey\_statistical\_2010},
  title = {Statistical Power Analysis with Missing Data: {{A}} Structural Equation Modeling Approach},
  author = {Davey, Adam and Savla, J},
  year = {2010},
  publisher = {{Routledge}},
  address = {{New York, NY}},
  keywords = {Missing observations (Statistics),Power analysis (Statistics),Statistical methods},
  lccn = {HA29 .D277 2010}
}

@article{Delucchi1999,
  title = {Small Sample Longitudinal Clinical Trial with Missing Data: {{A}} Comparison of Analytic Methods.},
  author = {Delucchi, Kevin, Dept of Psychiatry, San Francisco, CA, USBostrom, Alan, U California},
  year = {1999},
  volume = {4},
  issn = {1082-989X},
  doi = {<a href="http://dx.doi.org.libproxy.temple.edu/10.1037/1082-989X.4.2.158" target="_blank" id="linkhttp:dx.doi.org10.10371082-989X.4.2.158" title="http://dx.doi.org.libproxy.temple.edu/10.1037/1082-989X.4.2.158" data-title="http://dx.doi.org.libproxy.temple.edu/10.1037/1082-989X.4.2.158">http://dx.doi.org.libproxy.temple.edu/10.1037/1082-989X.4.2.158</a>},
  abstract = {The statistical power of 6 analytic methods was compared: t test and Mann-Whitney-Wilcoxon test on mean least squares regression slopes estimated for each participant, t test and Mann-Whitney-Wilcoxon test on pre-post differences, least squares multivariate repeated measures analysis of variance (MANOVA), and unbalanced repeated measures (URM) model with a 1st-order autoregressive covariance structure using restricted maximum-likelihood estimation. Factors included effect size, attrition pattern, sample size, and visit-to-visit correlation levels under sample size and dropout rates common to drug abuse treatment trials. In addition to its known effects of increasing N and effect size, the classic MANOVA approach was not as powerful as the other methods. Both t tests on pre-post change and the URM model performed well, and the results of using individual slope estimates as a summary statistic under an intent-to-treat model were surprisingly poor. (PsycINFO Database Record (c) 2012 APA, all rights reserved)},
  journal = {Psychological Methods},
  keywords = {clinical trials,experimental design,longitudinal},
  language = {English},
  number = {2}
}

@article{Dolan2005,
  title = {A Note on Normal Theory Power Calculation in {{SEM}} with Data Missing Completely at Random.},
  author = {Dolan, Conor and {van der Sluis}, Sophie and Grasman, Raoul},
  year = {2005},
  month = apr,
  volume = {12},
  pages = {245--262},
  publisher = {{Lawrence Erlbaum}},
  address = {{Dolan, Conor, Department of Psychology, University of Amsterdam, Roetersstraat 15, 1018WB, Amsterdam, Netherlands}},
  issn = {1070-5511},
  abstract = {We consider power calculation in structural equation modeling with data missing completely at random (MCAR). Muthen and Muthen (2002) recently demonstrated how power calculations with data MCAR can be carried out by means of a Monte Carlo study. Here we show that the method of Satorra and Saris (1985), which is based on the nonnull distribution of the (normal theory) log-likelihood ratio test, can also be used. Compared to a Monte Carlo study, this method is computationally less intensive. We discuss 2 ways to calculate power when data are MCAR, one based on multigroup analysis and summary statistics, the other based on transformed raw data. The latter method is quite simple to carry out. Four examples are presented. This article is limited to data MCAR. Generally MCAR is a strong assumption. We demonstrate that results of power analyses based on the MCAR assumption are not informative if the data are actually missing at random. (PsycINFO Database Record (c) 2012 APA, all rights reserved). (journal abstract)},
  journal = {Structural Equation Modeling},
  keywords = {data missing completely at random,likelihood ratio test,Maximum Likelihood,Monte Carlo study,normal theory power calculation,Satorra and Saris method,Statistical Analysis,structural equation modeling,Structural Equation Modeling DI - 10.1207/s153280},
  number = {2}
}

@article{enders_analyzing_2011,
  title = {Analyzing Longitudinal Data with Missing Values.},
  author = {Enders, Craig K.},
  year = {2011},
  volume = {56},
  pages = {267--288},
  issn = {1939-1544, 0090-5550},
  doi = {10.1037/a0025579},
  journal = {Rehabilitation Psychology},
  language = {en},
  number = {4}
}

@article{enders_estimating_2014,
  title = {Estimating Interaction Effects with Incomplete Predictor Variables.},
  author = {Enders, Craig K. and Baraldi, Amanda N. and Cham, Heining},
  year = {2014},
  volume = {19},
  pages = {39--55},
  issn = {1939-1463, 1082-989X},
  doi = {10.1037/a0035314},
  abstract = {The existing missing data literature does not provide a clear prescription for estimating interaction effects with missing data, particularly when the interaction involves a pair of continuous variables. In this article, we describe maximum likelihood and multiple imputation procedures for this common analysis problem. We outline 3 latent variable model specifications for interaction analyses with missing data. These models apply procedures from the latent variable interaction literature to analyses with a single indicator per construct (e.g., a regression analysis with scale scores). We also discuss multiple imputation for interaction effects, emphasizing an approach that applies standard imputation procedures to the product of 2 raw score predictors. We thoroughly describe the process of probing interaction effects with maximum likelihood and multiple imputation. For both missing data handling techniques, we outline centering and transformation strategies that researchers can implement in popular software packages, and we use a series of real data analyses to illustrate these methods. Finally, we use computer simulations to evaluate the performance of the proposed techniques.},
  file = {/Users/tub00573/Zotero/storage/2UBYHE8F/Enders et al. - 2014 - Estimating interaction effects with incomplete pre.pdf},
  journal = {Psychological Methods},
  language = {English},
  number = {1}
}

@article{enders_missing_2011-1,
  title = {Missing Not at Random Models for Latent Growth Curve Analyses.},
  author = {Enders, Craig K.},
  year = {2011},
  volume = {16},
  pages = {1--16},
  issn = {1939-1463, 1082-989X},
  doi = {10.1037/a0022640},
  file = {/Users/tub00573/Zotero/storage/SN4AUE6F/Enders - 2011 - Missing not at random models for latent growth cur.pdf},
  journal = {Psychological Methods},
  language = {en},
  number = {1}
}

@article{enders_multilevel_2016,
  title = {Multilevel Multiple Imputation: {{A}} Review and Evaluation of Joint Modeling and Chained Equations Imputation.},
  shorttitle = {Multilevel Multiple Imputation},
  author = {Enders, Craig K. and Mistler, Stephen A. and Keller, Brian T.},
  year = {2016},
  volume = {21},
  pages = {222--240},
  issn = {1939-1463, 1082-989X},
  doi = {10.1037/met0000063},
  abstract = {Although missing data methods have advanced in recent years, methodologists have devoted less attention to multilevel data structures where observations at level-1 are nested within higher-order organizational units at level-2 (e.g., individuals within neighborhoods; repeated measures nested within individuals; students nested within classrooms). Joint modeling and chained equations imputation are the principal imputation frameworks for single-level data, and both have multilevel counterparts. These approaches differ algorithmically and in their functionality; both are appropriate for simple random intercept analyses with normally distributed data, but they differ beyond that. The purpose of this paper is to describe multilevel imputation strategies and evaluate their performance in a variety of common analysis models. Using multiple imputation theory and computer simulations, we derive 4 major conclusions: (a) joint modeling and chained equations imputation are appropriate for random intercept analyses; (b) the joint model is superior for analyses that posit different within- and between-cluster associations (e.g., a multilevel regression model that includes a level-1 predictor and its cluster means, a multilevel structural equation model with different path values at level-1 and level-2); (c) chained equations imputation provides a dramatic improvement over joint modeling in random slope analyses; and (d) a latent variable formulation for categorical variables is quite effective. We use a real data analysis to demonstrate multilevel imputation, and we suggest a number of avenues for future research.},
  file = {/Users/tub00573/Zotero/storage/ECDAL27P/Enders et al. - 2016 - Multilevel multiple imputation A review and evalu.pdf},
  journal = {Psychological Methods},
  language = {English},
  number = {2}
}

@article{Enders2001,
  title = {The Impact of Nonnormality on Full Information Maximum-Likelihood Estimation for Structural Equation Models with Missing Data.},
  author = {Enders, C K},
  year = {2001},
  month = dec,
  volume = {6},
  pages = {352--70},
  issn = {1082-989X},
  doi = {<a href="javascript:__doLinkPostBack('','ss~~DI\%20\%2210.1037\%2F1082-989X.6.4.352\%22\%7C\%7Csl~~rl','');" title="Search for 10.1037/1082-989X.6.4.352" id="link10.10371082-989X.6.4.352">10.1037/1082-989X.6.4.352</a>},
  abstract = {A Monte Carlo simulation examined full information maximum-likelihood estimation (FIML) in structural equation models with nonnormal indicator variables. The impacts of 4 independent variables were examined (missing data algorithm, missing data rate, sample size, and distribution shape) on 4 outcome measures (parameter estimate bias, parameter estimate efficiency, standard error coverage, and model rejection rates). Across missing completely at random and missing at random patterns, FIML parameter estimates involved less bias and were generally more efficient than those of ad hoc missing data techniques. However, similar to complete-data maximum-likelihood estimation in structural equation modeling, standard errors were negatively biased and model rejection rates were inflated. Simulation results suggest that recently developed correctives for missing data (e.g., rescaled statistics and the bootstrap) can mitigate problems that stem from nonnormal data.},
  journal = {Psychological methods},
  keywords = {Data Collection,Data Collection: statistics \& numerical data,Experimental,Experimental: statistics \& numerical d,Humans,Likelihood Functions,Models,Monte Carlo Method,Psychological Tests,Psychological Tests: statistics \& numerical data,Psychology,Psychometrics,Reference Values,Reproducibility of Results,Statistical},
  language = {English},
  number = {4},
  pmid = {11778677}
}

@article{Enders2001a,
  title = {A Primer on Maximum Likelihood Algorithms Available for Use with Missing Data.},
  author = {Enders, Craig K},
  year = {2001},
  volume = {8},
  pages = {128--141},
  publisher = {{Lawrence Erlbaum}},
  address = {{US}},
  issn = {1070-5511},
  abstract = {Maximum likelihood algorithms for use with missing data are becoming commonplace in microcomputer packages. Specifically, 3 maximum likelihood algorithms are currently available in existing software packages: the multiple-group approach, full information maximum likelihood estimation, and the EM algorithm. Although they belong to the same family of estimator, confusion appears to exist over the differences among the 3 algorithms. This article provides a comprehensive, nontechnical overview of the 3 maximum likelihood algorithms. Multiple imputation, which is frequently used in conjunction with the EM algorithm, is also discussed. (PsycINFO Database Record (c) 2012 APA, all rights reserved)},
  journal = {Structural Equation Modeling},
  keywords = {Algorithms,Data Collection DI - 10.1207/S15328007SEM0801_7,maximum likelihood algorithms for use with missing},
  number = {1}
}

@article{Enders2001b,
  title = {The Performance of the Full Information Maximum Likelihood Estimator in Multiple Regression Models with Missing Data.},
  author = {Enders, Craig K},
  year = {2001},
  month = oct,
  volume = {61},
  pages = {713--740},
  publisher = {{Sage Publications}},
  address = {{US}},
  issn = {0013-1644},
  abstract = {A Monte Carlo simulation examined the performance of a recently available full information maximum likelihood (FIML) estimator in a multiple regression model with missing data. The effects of 4 independent variables were examined (missing data technique, missing data rate, sample size, and correlation magnitude) on 3 outcome measures: regression coefficient bias, R{$^2$} bias, and regression coefficient sampling variability. Three missing data patterns were examined based on Rubin's missing data theory: missing completely at random, missing at random, and a nonrandom pattern. Results indicate that FIML estimation was superior to the 3 ad hoc techniques (listwise deletion, pairwise deletion, and mean imputation) across the conditions studied. FIML parameter estimates generally had less bias and less sampling variability than the 3 ad hoc methods. (PsycINFO Database Record (c) 2012 APA, all rights reserved)},
  journal = {Educational and Psychological Measurement},
  keywords = {FIML,full information maximum likelihood estimator,Methodology,missing data,Models,Multiple Regression DI - 10.1177/0013164012197148,multiple regression models,performance},
  number = {5}
}

@article{Enders2001c,
  title = {The Relative Performance of Full Information Maximum Likelihood Estimation for Missing Data in Structural Equation Models.},
  author = {Enders, Craig K and Bandalos, Deborah L},
  year = {2001},
  volume = {8},
  pages = {430--457},
  publisher = {{Lawrence Erlbaum}},
  address = {{US}},
  issn = {1070-5511},
  abstract = {A Monte Carlo simulation examined the performance of 4 missing data methods in structural equation models: full information maximum likelihood (FIML), listwise deletion, pairwise deletion, and similar response pattern imputation. The effects of 3 independent variables were examined (factor loading magnitude, sample size, and missing data rate) on 4 outcome measures: convergence failures, parameter estimate bias, parameter estimate efficiency, and model goodness of fit. Results indicated that FIML estimation was superior across all conditions of the design. Under ignorable missing data conditions (missing completely at random and missing at random), FIML estimates were unbiased and more efficient than the other methods. In addition, FIML yielded the lowest proportion of convergence failures and provided near-optimal Type 1 error rates across both simulations. (PsycINFO Database Record (c) 2012 APA, all rights reserved). (journal abstract)},
  journal = {Structural Equation Modeling},
  keywords = {full information maximum likelihood estimation,listwise deletion,Maximum Likelihood,missing data,pairwise deletion,similar response pattern imputation,Statistical Data,Structural Equation Modeling DI - 10.1207/S153280,structural equation models},
  number = {3}
}

@article{Enders2002,
  title = {Applying the {{Bollen}}-{{Stine}} Bootstrap for Goodness-of-Fit Measures to Structural Equation Models with Missing Data.},
  author = {Enders, Craig K},
  year = {2002},
  month = jul,
  volume = {37},
  pages = {359--377},
  publisher = {{Lawrence Erlbaum}},
  address = {{Enders, Craig K., U Miami, School of Education, P. O. Box 248065, Coral Gables, FL, US, 33124-2040}},
  issn = {0027-3171},
  abstract = {Proposed a method for extending the Bollen-Stine bootstrap of model fit to structural equation models with missing data. Matrix algebra difficulties associated with an incomplete data matrix are circumvented by applying the Bollen-Stine transformation to each case (or group of cases sharing a common pattern of missing data) using reduced arrays that contain elements corresponding to the observed variables. A SAS macro program is provided for the purposes of implementing this procedure, and its' performance was assessed in a simulation that varied distribution shape, sample size, and the missing data rate. Compared to the unadjusted fit statistic, which produced dramatically inflated Type I error rates, the bootstrap yielded model rejection rates quite close to the nominal 5\% level, although rejection rates were conservative under small sample conditions. (PsycINFO Database Record (c) 2012 APA, all rights reserved)},
  journal = {Multivariate Behavioral Research},
  keywords = {Bollen-Stine bootstrap,Computer Software,Goodness of Fit,goodness-of-fit measures,Maximum Likelihood,missing data,SAS macro program,Statistical Analysis,Statistical Data DI - 10.1207/S15327906MBR3703_3,Structural Equation Modeling,structural equation models},
  number = {3}
}

@article{Enders2003,
  title = {Using the Expectation Maximization Algorithm to Estimate Coefficient Alpha for Scales with Item-Level Missing Data.},
  author = {Enders, Craig K},
  year = {2003},
  month = sep,
  volume = {8},
  pages = {322--37},
  issn = {1082-989X},
  doi = {10.1037/1082-989X.8.3.322},
  abstract = {A 2-step approach for obtaining internal consistency reliability estimates with item-level missing data is outlined. In the 1st step, a covariance matrix and mean vector are obtained using the expectation maximization (EM) algorithm. In the 2nd step, reliability analyses are carried out in the usual fashion using the EM covariance matrix as input. A Monte Carlo simulation examined the impact of 6 variables (scale length, response categories, item correlations, sample size, missing data, and missing data technique) on 3 different outcomes: estimation bias, mean errors, and confidence interval coverage. The 2-step approach using EM consistently yielded the most accurate reliability estimates and produced coverage rates close to the advertised 95\% rate. An easy method of implementing the procedure is outlined.},
  journal = {Psychological methods},
  keywords = {Algorithms,Humans,Models,Psychological,Psychology,Psychology: methods},
  language = {English},
  number = {3},
  pmid = {14596494}
}

@article{Enders2004,
  title = {Using an {{EM}} Covariance Matrix to Estimate Structural Equation Models with Missing Data: {{Choosing}} an Adjusted Sample Size to Improve the Accuracy of Inferences.},
  author = {Enders, Craig K and Peugh, James L},
  year = {2004},
  month = jan,
  volume = {11},
  pages = {1--19},
  publisher = {{Lawrence Erlbaum}},
  address = {{Enders, Craig K., U Nebraska, Educational Psychology, 222 Teachers College Hall, Lincoln, NE, US, 68588}},
  issn = {1070-5511},
  abstract = {Two methods, direct maximum likelihood (ML) and the expectation maximization (EM) algorithm, can be used to obtain ML parameter estimates for structural equation models with missing data (MD). Although the 2 methods frequently produce identical parameter estimates, it may be easier to satisfy missing at random assumptions using EM. However, no single value of N is applicable to the EM covariance matrix, and this may compromise inferences gained from the model fit statistic and parameter standard errors. The purpose of this study was to identify a value of N that provides accurate inferences when using EM. If all confirmatory factor analysis model indicators have MD, results suggest that the minimum N per covariance term yields honest Type 1 error rates. If MD are restricted to a subset of indicators, the minimum N per variance works well. With respect to standard errors, the harmonic mean N per variance term produces honest confidence interval coverage rates. (PsycINFO Database Record (c) 2012 APA, all rights reserved). (journal abstract)},
  journal = {Structural Equation Modeling},
  keywords = {Algorithms,confidence interval,confirmatory factor analysis,covariance matrix,error rates,Expectations,Inference DI - 10.1207/S15328007SEM1101_1,maximum likelihood,Maximum Likelihood,missing data,parameter estimates,sample size,standard errors,Statistical Analysis,structural equation,Structural Equation Modeling},
  number = {1}
}

@article{Enders2005,
  title = {An {{SAS}} Macro for Implementing the Modified {{Bollen}}-{{Stine}} Bootstrap for Missing Data: {{Implementing}} the Bootstrap Using Existing Structural Equation Modeling Software.},
  author = {Enders, Craig K},
  year = {2005},
  volume = {12},
  pages = {620--641},
  publisher = {{Lawrence Erlbaum}},
  address = {{Enders, Craig K., Department of Psychology, Arizona State University, Box 871104, Tempe, AZ, US, 85287-1104}},
  issn = {1070-5511},
  abstract = {The Bollen-Stine bootstrap can be used to correct for standard error and fit statistic bias that occurs in structural equation modeling (SEM) applications due to non normal data. The purpose of this article is to demonstrate the use of a custom SAS macro program that can be used to implement the Bollen-Stine bootstrap with existing SEM software. Although this article focuses on missing data, the macro can be used with complete data sets as well. A series of heuristic analyses are presented, along with detailed programming instructions for each of the commercial SEM software packages. (PsycINFO Database Record (c) 2012 APA, all rights reserved). (journal abstract)},
  journal = {Structural Equation Modeling},
  keywords = {Computer Software,Heuristic Modeling,missing data,modified Bollen-Stine bootstrap,SAS macro program,Statistical Analysis,Statistical Data,Structural Equation Modeling DI - 10.1207/s153280,structural equation modeling software},
  number = {4}
}

@article{Enders2008,
  title = {A Note on the Use of Missing Auxiliary Variables in Full Information Maximum Likelihood-Based Structural Equation Models.},
  author = {Enders, Craig K},
  year = {2008},
  month = jul,
  volume = {15},
  pages = {434--448},
  publisher = {{Taylor \& Francis}},
  address = {{Enders, Craig K., PO Box 871104, Tempe, AZ, US, 85287-1104}},
  issn = {1070-5511},
  abstract = {Recent missing data studies have argued in favor of an "inclusive analytic strategy" that incorporates auxiliary variables into the estimation routine, and Graham (2003) outlined methods for incorporating auxiliary variables into structural equation analyses. In practice, the auxiliary variables often have missing values, so it is reasonable to ask whether the inclusion of such variables will improve the estimation of model parameters. Simulation results indicated that the proportion of missing data and the missing data mechanism of the auxiliary variables had little impact on bias. Even when an auxiliary variable was missing not at random, bias was relegated to the auxiliary variable portion of the model, and did not propagate into the model of substantive interest. The study results suggest that the inclusion of an auxiliary variable is beneficial, even if the auxiliary variable has a substantial proportion of missing data. (PsycINFO Database Record (c) 2012 APA, all rights reserved). (journal abstract)},
  journal = {Structural Equation Modeling},
  keywords = {Estimation,Maximum Likelihood,maximum likelihood-based structural equation model,missing auxiliary variables,model parameters,Simulation,Structural Equation Modeling},
  number = {3}
}

@article{Enders2013,
  title = {Dealing with Missing Data in Developmental Research.},
  author = {Enders, Craig K},
  year = {2013},
  month = mar,
  volume = {7},
  pages = {27--31},
  publisher = {{Wiley-Blackwell Publishing Ltd.}},
  address = {{Enders, Craig K., Department of Psychology, Arizona State University, 871104, Tempe, AZ, US, 85287-1104}},
  issn = {1750-8592},
  abstract = {Approaches to handling missing data have improved dramatically in recent years and researchers can now choose from a variety of sophisticated analysis options. The methodological literature favors maximum likelihood and multiple imputation because these approaches offer substantial improvements over older approaches, including a strong theoretical foundation, less restrictive assumptions, and the potential for bias reduction and greater power. These benefits are especially important for developmental research where attrition is a pervasive problem. This article provides a brief introduction to modern methods for handling missing data and their application to developmental research. (PsycINFO Database Record (c) 2013 APA, all rights reserved). (journal abstract)},
  journal = {Child Development Perspectives},
  keywords = {Development,developmental research,Experimental Design,maximum likelihood,Maximum Likelihood DI - 10.1111/cdep.12008,missing data,Statistical Data},
  number = {1}
}

@article{Enders2013a,
  title = {A {{Bayesian}} Approach for Estimating Mediation Effects with Missing Data.},
  author = {Enders, Craig K and Fairchild, Amanda J and MacKinnon, David P},
  year = {2013},
  month = may,
  volume = {48},
  pages = {340--369},
  publisher = {{Taylor \& Francis}},
  address = {{Enders, Craig K., Department of Psychology, Arizona State University, Box 871104, Tempe, AZ, US, 85287-1104}},
  issn = {0027-3171},
  abstract = {Methodologists have developed mediation analysis techniques for a broad range of substantive applications, yet methods for estimating mediating mechanisms with missing data have been understudied. This study outlined a general Bayesian missing data handling approach that can accommodate mediation analyses with any number of manifest variables. Computer simulation studies showed that the Bayesian approach produced frequentist coverage rates and power estimates that were comparable to those of maximum likelihood with the bias-corrected bootstrap. We share an SAS macro that implements Bayesian estimation and use 2 data analysis examples to demonstrate its use. (PsycINFO Database Record (c) 2013 APA, all rights reserved). (journal abstract)},
  journal = {Multivariate Behavioral Research},
  keywords = {Bayesian analysis,computer simulation,Computer Simulation,Data Collection,Mediation,mediation analysis,missing data,Statistical Probability},
  number = {3}
}

@article{Estabrook2013,
  title = {A Comparison of Factor Score Estimation Methods in the Presence of Missing Data: {{Reliability}} and an Application to Nicotine Dependence.},
  author = {Estabrook, Ryne and Neale, Michael},
  year = {2013},
  month = jan,
  volume = {48},
  pages = {1--27},
  publisher = {{Taylor \& Francis}},
  address = {{Estabrook, Ryne, Virginia Commonwealth University, VIPBG, P.O. Box 980126, Richmond, VA, US, 23298}},
  issn = {0027-3171},
  abstract = {Factor score estimation is a controversial topic in psychometrics, and the estimation of factor scores from exploratory factor models has historically received a great deal of attention. However, both confirmatory factor models and the existence of missing data have generally been ignored in this debate. This article presents a simulation study that compares the reliability of sum scores, regression-based and expected posterior methods for factor score estimation for confirmatory factor models in the presence of missing data. Although all methods perform reasonably well with complete data, expected posterior-weighted (full) maximum likelihood methods are significantly more reliable than sum scores and regression estimators in the presence of missing data. Factor score reliability for complete data can be predicted by Guttman's 1955 formula for factor communality. Furthermore, factor score reliability for incomplete data can be reasonably approximated by communality raised to the 1/1-P (Missing) power. An empirical demonstration shows that the full maximum likelihood method best preserves the relationship between nicotine dependence and a genetic predictor under missing data. Implications and recommendations for applied research are discussed. (PsycINFO Database Record (c) 2013 APA, all rights reserved). (journal abstract)},
  journal = {Multivariate Behavioral Research},
  keywords = {confirmatory factor models,Estimation,Factor Analysis,factor score estimation methods,factor score reliability,missing data,Models,nicotine dependence,Nicotine DI - 10.1080/00273171.2012.730072,psychometrics,Psychometrics},
  number = {1}
}

@article{Feldman2012,
  title = {Modeling Achievement Trajectories When Attrition Is Informative},
  author = {Feldman, Betsy J and {Rabe-Hesketh}, Sophia},
  year = {2012},
  volume = {37},
  pages = {703--736},
  doi = {10.3102/1076998612458701},
  abstract = {In longitudinal education studies, assuming that dropout and missing data occur completely at random is often unrealistic. When the probability of dropout depends on covariates and observed responses (called missing at random [MAR]), or on values of responses that are missing (called informative or not missing at random [NMAR]), inappropriate analysis can cause biased estimates. NMAR requires explicit modeling of the missingness process together with the response variable. In this article, we review assumptions needed for consistent estimation of hierarchical linear growth models using common missing-data approaches. We also suggest a joint model for the longitudinal data and missingness process to handle the situation where data are NMAR. The different approaches are applied to the NELS:88 study, as well as simulated data. Results from the NELS:88 analyses were similar between the MAR and NMAR models. However, use of listwise deletion and mean imputation resulted in significant bias, both for the NELS:88 study and simulated data. Simulation results showed that incorrectly assuming MAR leads to greater bias for the growth-factor variance\textendash{}covariance matrix than for the growth factor means, the former being severe with as little as 10\% missing data and the latter with 40\% missing data when departure from MAR is strong.},
  journal = {Journal of Educational and Behavioral Statistics},
  number = {6}
}

@article{Furlow2005,
  title = {Meta-Analytic Methods of Pooling Correlation Matrices for Structural Equation Modeling under Different Patterns of Missing Data.},
  author = {Furlow, Carolyn F and Beretvas, S Natasha},
  year = {2005},
  month = jun,
  volume = {10},
  pages = {227--54},
  issn = {1082-989X},
  doi = {10.1037/1082-989X.10.2.227},
  abstract = {Three methods of synthesizing correlations for meta-analytic structural equation modeling (SEM) under different degrees and mechanisms of missingness were compared for the estimation of correlation and SEM parameters and goodness-of-fit indices by using Monte Carlo simulation techniques. A revised generalized least squares (GLS) method for synthesizing correlations, weighted-covariance GLS (W-COV GLS), was compared with univariate weighting with untransformed correlations (univariate r) and univariate weighting with Fisher's z-transformed correlations (univariate z). These 3 methods were crossed with listwise and pairwise deletion. Univariate z and W-COV GLS performed similarly, with W-COV GLS providing slightly better estimation of parameters and more correct model rejection rates. Missing not at random data produced high levels of relative bias in correlation and model parameter estimates and higher incorrect SEM model rejection rates. Pairwise deletion resulted in inflated standard errors for all synthesis methods and higher incorrect rejection rates for the SEM model with univariate weighting procedures.},
  file = {/Users/tub00573/Zotero/storage/A8H5M77H/Furlow, Beretvas - 2005 - Meta-analytic methods of pooling correlation matrices for structural equation modeling under different pattern.pdf},
  journal = {Psychological methods},
  keywords = {Humans,Meta-Analysis as Topic,MissingData,Models,Psychological,Psychology,Psychology: methods},
  language = {English},
  mendeley-tags = {MissingData},
  number = {2},
  pmid = {15998179}
}

@article{Gold2000,
  title = {Treatments of Missing Data: {{A Monte Carlo}} Comparison of {{RBHDI}}, Iterative Stochastic Regression Imputation, and Expectation-Maximization.},
  author = {Gold, Michael Steven and Bentler, Peter M},
  year = {2000},
  volume = {7},
  pages = {319--355},
  publisher = {{Lawrence Erlbaum}},
  address = {{US}},
  issn = {1070-5511},
  abstract = {This article describes a Monte Carlo investigation of 4 methods for treating incomplete data. Data sets conforming to a single structured model, but varying in sample size, distributional characteristics, and proportion of data deleted, were randomly produced. Resemblance-based hot-deck imputation, iterated stochastic regression imputation, structured-model expectation-maximization, and saturated-model expectation-maximization were applied to these data sets, and these methods were then compared in terms of their ability to reconstruct the original data, the intact-data variances and covariances, and the population variances and covariances. The results favored the expectation-maximization methods, regardless of sample size, proportion of data missing, and distributional characteristics of the data. The results are discussed with respect to practical considerations in the choice of missing-data treatment, including the possibilities of model misspecification, convergence failure, and the need to make data available to other investigators. (PsycINFO Database Record (c) 2012 APA, all rights reserved)},
  journal = {Structural Equation Modeling},
  keywords = {Data Processing,Methodology,Simulation,Structural Equation Modeling DI - 10.1207/S153280,treatment of missing data in structural equation m},
  number = {3}
}

@book{Gorsuch1983,
  title = {Factor Analysis},
  author = {Gorsuch, R L},
  year = {1983},
  edition = {Second},
  publisher = {{LEA}},
  address = {{Hillsdale, NJ}}
}

@article{graham_adding_2003,
  title = {Adding Missing-Data-Relevant Variables to Fiml-Based Structural Equation Models},
  author = {Graham, John W.},
  year = {2003},
  month = jan,
  volume = {10},
  pages = {80--100},
  issn = {1070-5511, 1532-8007},
  doi = {10.1207/S15328007SEM1001_4},
  journal = {Structural Equation Modeling: A Multidisciplinary Journal},
  language = {English},
  number = {1}
}

@article{graham_missing_2009,
  title = {Missing Data Analysis: {{Making}} It Work in the Real World},
  shorttitle = {Missing Data Analysis},
  author = {Graham, John W.},
  year = {2009},
  month = jan,
  volume = {60},
  pages = {549--576},
  issn = {0066-4308, 1545-2085},
  doi = {10.1146/annurev.psych.58.110405.085530},
  file = {/Users/tub00573/Zotero/storage/FEVBFAHX/Graham - 2009 - Missing Data Analysis Making It Work in the Real .pdf},
  journal = {Annual Review of Psychology},
  language = {English},
  number = {1}
}

@book{graham_missing_2012,
  title = {Missing Data: {{Analysis}} and Design},
  author = {Graham, John W.},
  year = {2012},
  publisher = {{Springer}},
  address = {{New York, NY}},
  doi = {10.1007/978-1-4614-4018-5},
  isbn = {978-1-4614-4017-8 978-1-4614-4018-5},
  language = {English},
  series = {Statistics for {{Social}} and {{Behavioral Sciences}}}
}

@article{Graham1996,
  title = {Maximizing the Usefulness of Data Obtained with Planned Missing Value Patterns: {{An}} Application of Maximum Likelihood Procedures.},
  author = {Graham, John W and Hofer, Scott M and MacKinnon, David P},
  year = {1996},
  volume = {31},
  pages = {197--218},
  publisher = {{Lawrence Erlbaum}},
  address = {{US}},
  issn = {0027-3171},
  abstract = {Uses a simulation example to show that maximum likelihood (ML) approaches and associated multiple imputations of missing data provide unbiased, efficient estimates of variance and covariance parameters in normally distributed and skewed data. The authors also examine parameter estimates obtained from mean replacement, single imputation, and pairwise deletion when data are missing completely at random (MCAR) and where nonrandom missingness is overlaid on the 3-form design. An example from an alcohol and drug abuse prevention program is analyzed using ML and pairwise estimation. A simulation is performed to indicate when it is better to choose to split scales across forms or keep scales complete within forms. Results show that ML estimation and multiple imputation methods produce the most efficient and least biased variance and covariance estimates for normally distributed and slightly skewed data when data are MCAR. (PsycINFO Database Record (c) 2012 APA, all rights reserved)},
  journal = {Multivariate Behavioral Research},
  keywords = {application of maximum likelihood multiple imputat,Maximum Likelihood,Statistical Data,Statistical Estimation DI - 10.1207/s15327906mbr3},
  number = {2}
}

@incollection{GrahamJohnW.2012Semw,
  title = {Structural Equation Modeling with Missing Data.},
  booktitle = {Handbook of Structural Equation Modeling /},
  author = {Graham, John W. and Hoffman, Donna L.},
  year = {2012},
  month = jan,
  pages = {277},
  publisher = {{Guilford Press,}},
  address = {{New York :}},
  isbn = {1-60623-077-8}
}

@article{Gross2000,
  title = {Bayesian Interval Estimation of Multiple Correlations with Missing Data: {{A Gibbs}} Sampling Approach.},
  author = {Gross, Alan L},
  year = {2000},
  volume = {35},
  pages = {201--227},
  publisher = {{Lawrence Erlbaum}},
  address = {{US}},
  issn = {0027-3171},
  abstract = {The estimation of the multiple correlation among variables is often of interest to social science researchers who conduct regression analyses. In this article, a Bayesian method for obtaining an interval estimate of the population squared multiple correlation from an incomplete multivariate normal data set is described. The method is applicable to data sets where values are missing on any combination of the dependent and independent variables. Further, the missing data need not be missing in a completely random fashion. The estimates are constructed using a Markov Chain Monte Carlo procedure known as Gibbs Sampling. The important issues of the convergence properties of the Gibbs sampler, the effect of the choice of a reference prior, and the empirical coverage probabilities of the estimates are considered in detail. Investigations using simulated data suggest that the proposed method can yield accurate interval estimates of the population squared multiple correlation. (PsycINFO Database Record (c) 2012 APA, all rights reserved)},
  journal = {Multivariate Behavioral Research},
  keywords = {Gibbs Sampling approach to Bayesian interval estim,Social Sciences,Statistical Correlation,Statistical Data,Statistical Estimation,Statistical Probability,Statistical Regression DI - 10.1207/S15327906MBR3},
  number = {2}
}

@article{Guo2014,
  title = {Multi-Index Regression Models with Missing Covariates at Random.},
  author = {Guo, Xu and Xu, Wangli and Zhu, Lixing},
  year = {2014},
  month = jan,
  volume = {123},
  pages = {345--363},
  publisher = {{Elsevier Science}},
  address = {{Zhu, Lixing}},
  issn = {0047-259X},
  abstract = {This paper considers estimation of the semiparametric multi-index model with missing covariates at random. A weighted estimating equation is suggested by invoking the inverse selection probability approach, and estimators of the indices are respectively defined when the selection probability is known in advance, is estimated parametrically and nonparametrically. The consistency is provided. For the single-index model, the large sample properties show that the estimators with both parametric and nonparametric plug-in estimations can play an important role to achieve smaller limiting variances than the estimator with the true selection probability. Simulation studies are carried out to assess the finite sample performance of the proposed estimators. The proposed methods are applied to an AIDS clinical trials dataset to examine which method could be more efficient. A horse colic dataset is also analyzed for illustration. (PsycINFO Database Record (c) 2014 APA, all rights reserved). (journal abstract)},
  journal = {Journal of Multivariate Analysis},
  keywords = {Analysis of Covariance,datasets,missing covariates,Models,probability,Probability,regression models,Statistical Data,statistical estimation,Statistical Estimation,Statistical Regression}
}

@article{Hamaker2012,
  title = {Regime Switching State-Space Models Applied to Psychological Processes: {{Handling}} Missing Data and Making Inferences.},
  author = {Hamaker, E L and Grasman, R P P P},
  year = {2012},
  month = apr,
  volume = {77},
  pages = {400--422},
  publisher = {{Springer}},
  address = {{Hamaker, E. L., Faculty of Social and Behavioural Sciences, Utrecht University, P.O. Box 80140, 3508 TC, Utrecht, Netherlands}},
  issn = {0033-3123},
  abstract = {Many psychological processes are characterized by recurrent shifts between distinct regimes or states. Examples that are considered in this paper are the switches between different states associated with premenstrual syndrome, hourly fluctuations in affect during a major depressive episode, and shifts between a ``hot hand'' and a ``cold hand'' in a top athlete. We model these processes with the regime switching state-space model proposed by Kim (J. Econom. 60:1\textendash{}22, 1994), which results in both maximum likelihood estimates for the model parameters and estimates of the latent variables and the discrete states of the process. However, the current algorithm cannot handle missing data, which limits its applicability to psychological data. Moreover, the performance of standard errors for the purpose of making inferences about the parameter estimates is yet unknown. In this paper we modify Kim's algorithm so it can handle missing data and we perform a simulation study to investigate its performance in (relatively) short time series in cases of different kinds of missing data and in case of complete data. Finally, we apply the regime switching state-space model to the three empirical data sets described above. (PsycINFO Database Record (c) 2012 APA, all rights reserved). (journal abstract)},
  journal = {Psychometrika},
  keywords = {Algorithms,Inference,Kim's algorithm,making inferences,Maximum Likelihood,maximum likelihood estimates,missing data,premenstrual syndrome,Premenstrual Syndrome,psychological processes,Statistical Data,Statistical Estimation,switching state space models},
  number = {2}
}

@article{Hao2001,
  title = {Inferences on a Normal Covariance Matrix and Generalized Variance with Monotone Missing Data.},
  author = {Hao, Jian and Krishnamoorthy, K},
  year = {2001},
  month = jul,
  volume = {78},
  pages = {62--82},
  publisher = {{Elsevier Science}},
  address = {{Krishnamoorthy, K., Department of Mathematics, University of Louisiana at Lafayette, Lafayette, LA, US, 70504-1010}},
  issn = {0047-259X},
  abstract = {The problems of testing a normal covariance matrix and an interval estimation of generalized variance when the data are missing from subsets of components are considered. The likelihood ratio test statistic for testing the covariance matrix is equal to a specified matrix, and its asymptotic null distribution is derived when the data matrix is of a monotone pattern. The validity of the asymptotic null distribution and power analysis are performed using simulation. The problem of testing the normal mean vector and a covariance matrix equal to a given vector and matrix is also addressed. Further, an approximate confidence interval for the generalized variance is given. Numerical studies show that the proposed interval estimation procedure is satisfactory even for small samples. The results are illustrated using simulated data. (PsycINFO Database Record (c) 2012 APA, all rights reserved). (journal abstract)},
  journal = {Journal of Multivariate Analysis},
  keywords = {Analysis of Covariance,generalized variance,monotone missing data,monotone pattern,normal covariance matrix,null distribution,simulation,Simulation,Statistical Data,Statistics DI - 10.1006/jmva.2000.1939,testing},
  number = {1}
}

@article{hedeker_application_1997,
  title = {Application of Random-Effects Pattern-Mixture Models for Missing Data in Longitudinal Studies.},
  author = {Hedeker, Donald and Gibbons, Robert D.},
  year = {1997},
  volume = {2},
  pages = {64--78},
  issn = {1939-1463, 1082-989X},
  doi = {10.1037/1082-989X.2.1.64},
  file = {/Users/tub00573/Zotero/storage/8AVWJA2Z/ContentServer (2).pdf;/Users/tub00573/Zotero/storage/H3U3KXJU/Hedeker and Gibbons - 1997 - Application of random-effects pattern-mixture mode.pdf},
  journal = {Psychological Methods},
  language = {English},
  number = {1}
}

@article{henson_use_2006,
  title = {Use of Exploratory Factor Analysis in Published Research: {{Common}} Errors and Some Comment on Improved Practice},
  shorttitle = {Use of Exploratory Factor Analysis in Published Research},
  author = {Henson, Robin K. and Roberts, J. Kyle},
  year = {2006},
  month = jun,
  volume = {66},
  pages = {393--416},
  issn = {0013-1644, 1552-3888},
  doi = {10.1177/0013164405282485},
  file = {/Users/tub00573/Zotero/storage/PXJACZT5/Henson and Roberts - 2006 - Use of Exploratory Factor Analysis in Published Re.pdf},
  journal = {Educational and Psychological Measurement},
  language = {English},
  number = {3}
}

@article{Hershberger2003,
  title = {A Note on Determining the Number of Imputations for Missing Data.},
  author = {Hershberger, Scott L and Fisher, Dennis G},
  year = {2003},
  month = oct,
  volume = {10},
  pages = {648--650},
  publisher = {{Lawrence Erlbaum}},
  address = {{Hershberger, Scott L., California State U, Long Beach, Dept of Psychology, 1250 Bellflower Boulevard, Long Beach, CA, US, 90840}},
  issn = {1070-5511},
  abstract = {A desirable method for imputing missing data when the missing data mechanism is ignorable is random imputation. Imputation generally involves regressing each variable with missing data onto all the other variables. Single random imputation involves creating one data set in which each of the missing values is imputed by adding a random error term from the residual distribution of each imputed variable. Adding a random error term reduces the bias in standard errors of parameter estimates ordinarily observed under traditional methods of imputation (Schafer, 1997). However, even single random imputation produces standard errors that are generally biased downward and parameter estimates that are relatively inefficient. Improvements in bias and efficiency occur with multiple random imputation in which the imputation process is done more than once, producing multiple data sets whose parameter estimates and standard errors are averaged (Rubin, 1987). Many structural equation modeling programs (e.g., AMOS; Arbuckle, 1997) are now able to compute multiple random imputations for missing data. In this note, a suggestion is given based on simple random sampling theory as to how one can determine the number of imputations to perform. (PsycINFO Database Record (c) 2012 APA, all rights reserved)},
  journal = {Structural Equation Modeling},
  keywords = {Error of Measurement,missing data,multiple random imputation,parameter estimates,single random imputation,standard errors,Statistical Data,Statistical Estimation,structural equation modeling,Structural Equation Modeling DI - 10.1207/S153280},
  number = {4}
}

@article{Hill2001,
  title = {Accommodating Missing Data in Mixture Models for Classification by Opinion-Changing Behavior.},
  author = {Hill, Jennifer L},
  year = {2001},
  volume = {26},
  pages = {233--268},
  publisher = {{American Educational Research Assn}},
  address = {{Hill, Jennifer L.}},
  issn = {1076-9986},
  abstract = {Popular theories in political science regarding opinion-changing behavior postulate the existence of one or both of two broad categories of people: those with stable opinions over time; and those who appear to hold no solid opinion and, when asked to make a choice, do so seemingly at random. The model presented here explores evidence for a third category: durable changers. People in this group will change their opinions in a rational, informed manner after being exposed to new information. Survey data collected at four time points over nearly two years track Swiss citizens' readiness to support pollution- reduction policies. The authors analyzed the data using finite mixture models that allow estimation of the percentage in the poluation falling in each category for each question as well as the frequency of certain types of relevant behaviors within each category. These models extend the finite mixture model structure used in J. L. Hill and H. Kriesi (200la,b) to accommodate missing response data. This extension increases the sample size by nearly 60\% and weakens the missing-data assumptions required. The authors describe augmented models and fitting algorithms corresponding to different assumptions about the missing-data mechanism as well as the differences in results obtained. (PsycINFO Database Record (c) 2012 APA, all rights reserved). (journal abstract)},
  journal = {Journal of Educational and Behavioral Statistics},
  keywords = {Attitude Change,classification,Data Collection,durable changers,estimation,Mathematical Modeling,missing data,mixture models,opinion-changing behavior,Statistical Estimation DI - 10.3102/1076998602600},
  number = {2}
}

@article{horn_rationale_1965,
  title = {A Rationale and Test for the Number of Factors in Factor Analysis},
  author = {Horn, John L.},
  year = {1965},
  month = jun,
  volume = {30},
  pages = {179--185},
  issn = {0033-3123, 1860-0980},
  doi = {10.1007/BF02289447},
  journal = {Psychometrika},
  language = {English},
  number = {2}
}

@article{Huang2010,
  title = {Semiparametric Analysis Based on Weighted Estimating Equations for Transformation Models with Missing Covariates.},
  author = {Huang, Bin and Wang, Qihua},
  year = {2010},
  month = oct,
  volume = {101},
  pages = {2078--2090},
  publisher = {{Elsevier Science}},
  address = {{Wang, Qihua, Academy of Mathematics and Systems Science, Chinese Academy of Science, Beijing, China, 100190}},
  issn = {0047-259X},
  abstract = {Missing covariate data are very common in regression analysis. In this paper, the weighted estimating equation method (Qi et al., 2005) [25] is used to extend the so-called unified estimation procedure (Chen et al., 2002) [4] for linear transformation models to the case of missing covariates. The non-missingness probability is estimated nonparametrically by the kernel smoothing technique. Under missing at random, the proposed estimators are shown to be consistent and asymptotically normal, with the asymptotic variance estimated consistently by the usual plug-in method. Moreover, the proposed estimators are more efficient than the weighted estimators with the inverse of true non-missingness probability as weight. Finite sample performance of the estimators is examined via simulation and a real dataset is analyzed to illustrate the proposed methods. (PsycINFO Database Record (c) 2012 APA, all rights reserved). (journal abstract)},
  journal = {Journal of Multivariate Analysis},
  keywords = {missing covariates,semiparametric analysis,Simulation,Statistical Weighting,Stimulus Parameters,transformation models,weighted estimating equations},
  number = {9}
}

@article{Jamshidian2008,
  title = {Postmodeling Sensitivity Analysis to Detect the Effect of Missing Data Mechanisms.},
  author = {Jamshidian, Mortaza and Mata, Matthew},
  year = {2008},
  month = jul,
  volume = {43},
  pages = {432--452},
  publisher = {{Taylor \& Francis}},
  address = {{Jamshidian, Mortaza, Department of Mathematics, California State University, Fullerton, CA, US, 92834}},
  issn = {0027-3171},
  abstract = {Incomplete or missing data is a common problem in almost all areas of empirical research. It is well known that simple and ad hoc methods such as complete case analysis or mean imputation can lead to biased and/or inefficient estimates. The method of maximum likelihood works well; however, when the missing data mechanism is not one of missing completely at random (MCAR) or missing at random (MAR), it too can result in incorrect inference. Statistical tests for MCAR have been proposed, but these are restricted to a certain class of problems. The idea of sensitivity analysis as a means to detect the missing data mechanism has been proposed in the statistics literature in conjunction with selection models where conjointly the data and missing data mechanism are modeled. Our approach is different here in that we do not model the missing data mechanism but use the data at hand to examine the sensitivity of a given model to the missing data mechanism. Our methodology is meant to raise a flag for researchers when the assumptions of MCAR (or MAR) do not hold. To our knowledge, no specific proposal for sensitivity analysis has been set forth in the area of structural equation models (SEM). This article gives a specific method for performing postmodeling sensitivity analysis using a statistical test and graphs. A simulation study is performed to assess the methodology in the context of structural equation models. This study shows success of the method, especially when the sample size is 300 or more and the percentage of missing data is 20\% or more. The method is also used to study a set of real data measuring physical and social self-concepts in 463 Nigerian adolescents using a factor analysis model. (PsycINFO Database Record (c) 2012 APA, all rights reserved). (journal abstract)},
  journal = {Multivariate Behavioral Research},
  keywords = {Adolescent Development,adolescents,missing data mechanisms,postmodeling sensitivity analysis,self concept,Self Concept,Simulation,Statistical Data,statistical tests,Statistical Tests,Structural Equation Modeling,structural equation models},
  number = {3}
}

@article{Jelicic2009,
  title = {Use of Missing Data Methods in Longitudinal Studies: {{The}} Persistence of Bad Practices in Developmental Psychology.},
  author = {Jeli{\v c}i{\'c}, Helena and Phelps, Erin and Lerner, Richard M},
  year = {2009},
  month = jul,
  volume = {45},
  pages = {1195--1199},
  publisher = {{American Psychological Association}},
  address = {{Jeli{\v c}i{\'c}, Helena, Institute of Education, University of London, 15 Woburn Square, London, United Kingdom, WC1H 0NS}},
  issn = {0012-1649},
  abstract = {Developmental science rests on describing, explaining, and optimizing intraindividual changes and, hence, empirically requires longitudinal research. Problems of missing data arise in most longitudinal studies, thus creating challenges for interpreting the substance and structure of intraindividual change. Using a sample of reports of longitudinal studies obtained from three flagship developmental journals\textemdash{}Child Development, Developmental Psychology, and Journal of Research on Adolescence\textemdash{}we examined the number of longitudinal studies reporting missing data and the missing data techniques used. Of the 100 longitudinal studies sampled, 57 either reported having missing data or had discrepancies in sample sizes reported for different analyses. The majority of these studies (82\%) used missing data techniques that are statistically problematic (either listwise deletion or pairwise deletion) and not among the methods recommended by statisticians (i.e., the direct maximum likelihood method and the multiple imputation method). Implications of these results for developmental theory and application, and the need for understanding the consequences of using statistically inappropriate missing data techniques with actual longitudinal data sets, are discussed. (PsycINFO Database Record (c) 2012 APA, all rights reserved). (journal abstract)},
  journal = {Developmental Psychology},
  keywords = {developmental psychology,Developmental Psychology,direct maximum likelihood,longitudinal data set,Longitudinal Studies,Maximum Likelihood,Methodology,missing data,multiple imputation,Statistical Data},
  number = {4}
}

@article{jo_handling_2010,
  title = {Handling Missing Data in Randomized Experiments with Noncompliance},
  author = {Jo, Booil and Ginexi, Elizabeth M. and Ialongo, Nicholas S.},
  year = {2010},
  month = dec,
  volume = {11},
  pages = {384--396},
  issn = {1389-4986, 1573-6695},
  doi = {10.1007/s11121-010-0175-4},
  file = {/Users/tub00573/Zotero/storage/M887FPB4/Jo et al. - 2010 - Handling Missing Data in Randomized Experiments wi.pdf},
  journal = {Prevention Science},
  language = {English},
  number = {4}
}

@book{jolliffe_principal_2002,
  title = {Principal Component Analysis},
  author = {Jolliffe, I. T},
  year = {2002},
  publisher = {{Springer}},
  address = {{New York}},
  isbn = {978-0-387-22440-4},
  language = {English}
}

@article{juster_overview_1995,
  title = {An Overview of the Health and Retirement Study},
  author = {Juster, F. Thomas and Suzman, Richard},
  year = {1995},
  volume = {30},
  pages = {S7},
  issn = {0022166X},
  doi = {10.2307/146277},
  file = {/Users/tub00573/Zotero/storage/3SSH85I8/Juster and Suzman - 1995 - An Overview of the Health and Retirement Study.pdf},
  journal = {The Journal of Human Resources},
  language = {English}
}

@article{Kadengye2012,
  title = {Simple Imputation Methods versus Direct Likelihood Analysis for Missing Item Scores in Multilevel Educational Data.},
  author = {Kadengye, Damazo T., Faculty of Psychology and Educational Sciences, Katholieke Universiteit Leuven, Belgium, Trevor.Kadengye@kuleuven-kortrijk.be Cools, Wilfried, ITEC-IBBT, K. U. Leuven, Kortrijk, BelgiumCeulemans, Eva, Katholieke Universiteit Leuven, K, Kortrijk},
  year = {2012},
  volume = {44},
  issn = {1554-351X},
  doi = {<a href="http://dx.doi.org.libproxy.temple.edu/10.3758/s13428-011-0157-x" target="_blank" id="linkhttp:dx.doi.org10.3758s13428-011-0157-x" title="http://dx.doi.org.libproxy.temple.edu/10.3758/s13428-011-0157-x" data-title="http://dx.doi.org.libproxy.temple.edu/10.3758/s13428-011-0157-x">http://dx.doi.org.libproxy.temple.edu/10.3758/s13428-011-0157-x</a>},
  abstract = {Missing data, such as item responses in multilevel data, are ubiquitous in educational research settings. Researchers in the item response theory (IRT) context have shown that ignoring such missing data can create problems in the estimation of the IRT model parameters. Consequently, several imputation methods for dealing with missing item data have been proposed and shown to be effective when applied with traditional IRT models. Additionally, a nonimputation direct likelihood analysis has been shown to be an effective tool for handling missing observations in clustered data settings. This study investigates the performance of six simple imputation methods, which have been found to be useful in other IRT contexts, versus a direct likelihood analysis, in multilevel data from educational settings. Multilevel item response data were simulated on the basis of two empirical data sets, and some of the item scores were deleted, such that they were missing either completely at random or simply at random. An explanatory IRT model was used for modeling the complete, incomplete, and imputed data sets. We showed that direct likelihood analysis of the incomplete data sets produced unbiased parameter estimates that were comparable to those from a complete data analysis. Multiple-imputation approaches of the two-way mean and corrected item mean substitution methods displayed varying degrees of effectiveness in imputing data that in turn could produce unbiased parameter estimates. The simple random imputation, adjusted random imputation, item means substitution, and regression imputation methods seemed to be less effective in imputing missing item scores in multilevel data settings. (PsycINFO Database Record (c) 2012 APA, all rights reserved)},
  journal = {Behavior Research Methods},
  keywords = {education,item response theory,multivariate anal},
  language = {English},
  number = {2}
}

@article{kaiser_application_1960,
  title = {The Application of Electronic Computers to Factor Analysis},
  author = {Kaiser, Henry F.},
  year = {1960},
  month = apr,
  volume = {20},
  pages = {141--151},
  issn = {0013-1644, 1552-3888},
  doi = {10.1177/001316446002000116},
  journal = {Educational and Psychological Measurement},
  language = {English},
  number = {1}
}

@article{Kano2011,
  title = {Analysis of {{NMAR}} Missing Data without Specifying Missing-Data Mechanisms in a Linear Latent Variate Model.},
  author = {Kano, Yutaka, Graduate School of Engineering Science, Osaka University, Toyonaka, Japan, kano@sigmath.es.osaka-u.ac.jp Takai, Keiji, Division of Mathematical Science, Graduate School of Engineering Science, Osaka University, To, Division of Mathematical Science},
  year = {2011},
  volume = {102},
  issn = {0047-259X},
  doi = {<a href="http://dx.doi.org.libproxy.temple.edu/10.1016/j.jmva.2011.04.007" target="_blank" id="linkhttp:dx.doi.org10.1016j.jmva.2011.04.007" title="http://dx.doi.org.libproxy.temple.edu/10.1016/j.jmva.2011.04.007" data-title="http://dx.doi.org.libproxy.temple.edu/10.1016/j.jmva.2011.04.007">http://dx.doi.org.libproxy.temple.edu/10.1016/j.jmva.2011.04.007</a>},
  abstract = {It is natural to assume that a missing-data mechanism depends on latent variables in the analysis of incomplete data in latent variate modeling because latent variables are error-free and represent key notions investigated by applied researchers. Unfortunately, the missing-data mechanism is then not missing at random (NMAR). In this article, a new estimation method is proposed, which leads to consistent and asymptotically normal estimators for all parameters in a linear latent variate model, where the missing mechanism depends on the latent variables and no concrete functional form for the missing-data mechanism is used in estimation. The method to be proposed is a type of multi-sample analysis with or without mean structures, and hence, it is easy to implement. Complete-case analysis is shown to produce consistent estimators for some important parameters in the model. (PsycINFO Database Record (c) 2012 APA, all rights reserved)},
  journal = {Journal of Multivariate Analysis},
  keywords = {analysis,error analysis,experimentation,models},
  language = {English},
  number = {9}
}

@article{Kim2002,
  title = {Tests of Homogeneity of Means and Covariance Matrices for Multivariate Incomplete Data},
  author = {Kim, Kevin H. and Bentler, Peter M.},
  year = {2002},
  month = dec,
  volume = {67},
  pages = {609--623},
  issn = {0033-3123},
  journal = {Psychometrika},
  number = {4}
}

@article{Kolb1996,
  title = {Correcting for Nonresponse in Latent Class Analysis.},
  author = {Kolb, Rita R and Dayton, C Mitchell},
  year = {1996},
  volume = {31},
  pages = {7--32},
  publisher = {{Lawrence Erlbaum}},
  address = {{US}},
  issn = {0027-3171},
  abstract = {Investigated the application of the expectation-maximization (EM) algorithm for correcting for nonresponse in latent class models (LCMs). Of interest was how the distributions of estimates for LCM parameters were affected by the mechanism that precipitated missing data and by the proportion of nonresponse. Monte Carlo methods were used to assess bias in parameter estimates under various assumptions concerning the mechanism for missingness including cases where missingness was not at random. For LCMs with missing data, the EM algorithm provides parameter estimates that display relatively little bias even when the missing mechanism violates the randomness conditions. Findings suggest practical limits for the utility of the EM algorithm in terms of sample size and nonresponse rate. (PsycINFO Database Record (c) 2012 APA, all rights reserved)},
  journal = {Multivariate Behavioral Research},
  keywords = {Algorithms,Multivariate Analysis,Statistical Validity DI - 10.1207/s15327906mbr310,validity of expectation maximization algorithm for},
  number = {1}
}

@article{Kromrey1994,
  title = {Nonrandomly Missing Data in Multiple Regression: {{An}} Empirical Comparison of Common Missing-Data Treatments.},
  author = {Kromrey, Jeffrey D and Hines, Constance V},
  year = {1994},
  volume = {54},
  pages = {573--593},
  publisher = {{Sage Publications}},
  address = {{US}},
  issn = {0013-1644},
  abstract = {Investigated the effects of nonrandomly missing data in 2 predictor regression analyses and the differences in effectiveness of 5 common treatments of missing data on estimates of R\textendash{}2 and of each of the 2 standardized regression weights. Bootstrap samples of 50, 100, and 200 were drawn from 3 sets of actual field data on academic achievement, Likert-type ratings, and psychological traits. Nonrandomly missing data were created, and the parameter estimates were compared with those obtained from the same samples with no missing data. Results indicate that 3 imputation procedures produced biased estimates of R\textendash{}2 and both regression weights. Two deletion procedures provided accurate parameter estimates with up to 30\% of the data missing. (PsycINFO Database Record (c) 2012 APA, all rights reserved)},
  journal = {Educational and Psychological Measurement},
  keywords = {Multiple Regression,nonrandomly missing data,parameter estimates of 2 predictor regression mode,Statistical Data,Statistical Estimation,Statistical Sample Parameters DI - 10.1177/001316},
  number = {3}
}

@book{Lawley1971,
  title = {Factor Analysis as a Statistical Method},
  author = {Lawley, D N and Maxwell, A E},
  year = {1971},
  language = {English}
}

@article{Lawley1973,
  title = {Regression Ana Factor Analysis},
  author = {Lawley, D N and Maxwell, A E},
  year = {1973},
  month = aug,
  volume = {60},
  pages = {331--338},
  issn = {0006-3444},
  abstract = {A basic model of factor analysis is employed in the estimation of multiple correlation coefficients and partial regression weights. Estimators are derived for situations in which some or all of the independent variates are subject to errors in measurement. The effect of the errors is indicated and the problem of bias in the estimators is considered. In one special case it is shown how a best subset of the independent variates of any size can readily be found for data under analysis.},
  journal = {Biometrika},
  number = {2}
}

@article{Lee2006,
  title = {Bayesian Analysis of Nonlinear Structural Equation Models with Nonignorable Missing Data.},
  author = {Lee, Sik-Yum and Tang, Nian-Sheng},
  year = {2006},
  month = sep,
  volume = {71},
  pages = {541--564},
  publisher = {{Springer}},
  address = {{Lee, Sik-Yum, Department of Statistics, Chinese University of Hong Kong, N.T., Shatin, Hong Kong}},
  issn = {0033-3123},
  abstract = {A Bayesian approach is developed for analyzing nonlinear structural equation models with non-ignorable missing data. The nonignorable missingness mechanism is specified by a logistic regression model. A hybrid algorithm that combines the Gibbs sampler and the Metropolis-Hastings algorithm is used to produce the joint Bayesian estimates of structural parameters, latent variables, parameters in the nonignorable missing model, as well as their standard errors estimates. A goodness-of-fit statistic for assessing the plausibility of the posited nonlinear structural equation model is introduced, and a procedure for computing the Bayes factor for model comparison is developed via path sampling. Results obtained with respect to different missing data models, and different prior inputs are compared via simulation studies. In particular, it is shown that in the presence of nonignorable missing data, results obtained by the proposed method with a nonignorable missing data model are significantly better than those that are obtained under the missing at random assumption. A real example is presented to illustrate the newly developed Bayesian methodologies. (PsycINFO Database Record (c) 2012 APA, all rights reserved). (journal abstract)},
  journal = {Psychometrika},
  keywords = {Algorithms,Bayes factor,Gibbs sampler,Logistic Regression,Metropolis-Hayes algorithm,nonignorable missing data,path sampling,Statistical Data,Statistical Probability,Structural Equation Modeling},
  number = {3}
}

@article{Lee2008,
  title = {A Robust {{Bayesian}} Approach for Structural Equation Models with Missing Data.},
  author = {Lee, Sik-Yum and Xia, Ye-Mao},
  year = {2008},
  month = sep,
  volume = {73},
  pages = {343--364},
  publisher = {{Springer}},
  address = {{Lee, Sik-Yum, Department of Statistics, Chinese University of Hong Kong, Shatin, Hong Kong}},
  issn = {0033-3123},
  abstract = {In this paper, normal/independent distributions, including but not limited to the multivariate t distribution, the multivariate contaminated distribution, and the multivariate slash distribution, are used to develop a robust Bayesian approach for analyzing structural equation models with complete or missing data. In the context of a nonlinear structural equation model with fixed covariates, robust Bayesian methods are developed for estimation and model comparison. Results from simulation studies are reported to reveal the characteristics of estimation. The methods are illustrated by using a real data set obtained from diabetes patients. (PsycINFO Database Record (c) 2012 APA, all rights reserved). (journal abstract)},
  journal = {Psychometrika},
  keywords = {missing data,Multivariate Analysis,multivariate t distribution,Normal Distribution,normal distributions,robust Bayesian approach,Statistical Data,Statistical Probability,Structural Equation Modeling,structural equation models},
  number = {3}
}

@article{Liang2008,
  title = {Generalized Partially Linear Models with Missing Covariates.},
  author = {Liang, Hua},
  year = {2008},
  month = may,
  volume = {99},
  pages = {880--895},
  publisher = {{Elsevier Science}},
  address = {{Liang, Hua, Department of Biostatistics and Computational Biology, University of Rochester Medical Center, Rochester, NY, US, 14642}},
  issn = {0047-259X},
  abstract = {In this article we study a semiparametric generalized partially linear model when the covariates are missing at random. We propose combining local linear regression with the local quasilikelihood technique and weighted estimating equation to estimate the parameters and nonparameters when the missing probability is known or unknown. We establish normality of the estimators of the parameter and asymptotic expansion for the estimators of the nonparametric part. We apply the proposed models and methods to a study of the relation between virologic and immunologic responses in AIDS clinical trials, in which virologic response is classified into binary variables. We also give simulation results to illustrate our approach. (PsycINFO Database Record (c) 2012 APA, all rights reserved). (journal abstract)},
  journal = {Journal of Multivariate Analysis},
  keywords = {Analysis of Covariance,generalized partially linear models,Linear Perspective,missing covariates,Models,Parametric Statistical Tests,semiparametric model},
  number = {5}
}

@article{little_prevention_2012,
  title = {The Prevention and Treatment of Missing Data in Clinical Trials},
  author = {Little, Roderick J. and D'Agostino, Ralph and Cohen, Michael L. and Dickersin, Kay and Emerson, Scott S. and Farrar, John T. and Frangakis, Constantine and Hogan, Joseph W. and Molenberghs, Geert and Murphy, Susan A. and Neaton, James D. and Rotnitzky, Andrea and Scharfstein, Daniel and Shih, Weichung J. and Siegel, Jay P. and Stern, Hal},
  year = {2012},
  month = oct,
  volume = {367},
  pages = {1355--1360},
  issn = {0028-4793, 1533-4406},
  doi = {10.1056/NEJMsr1203730},
  file = {/Users/tub00573/Zotero/storage/EVNILKAU/Little et al. - 2012 - The Prevention and Treatment of Missing Data in Cl.pdf},
  journal = {New England Journal of Medicine},
  language = {English},
  number = {14}
}

@book{little_statistical_2002,
  title = {Statistical Analysis with Missing Data},
  author = {Little, Roderick J. A. and Rubin, Donald B.},
  year = {2002},
  edition = {2nd ed},
  publisher = {{Wiley}},
  address = {{Hoboken, N.J}},
  isbn = {978-0-471-18386-0},
  keywords = {Mathematical statistics,Missing observations (Statistics)},
  lccn = {QA276 .L57 2002},
  series = {Wiley Series in Probability and Statistics}
}

@article{Little2013,
  title = {Planned Missing Data Designs for Developmental Researchers.},
  author = {Little, Todd D and Rhemtulla, Mijke},
  year = {2013},
  month = dec,
  volume = {7},
  pages = {199--204},
  publisher = {{Wiley-Blackwell Publishing Ltd.}},
  address = {{Little, Todd D., Center for Research Methods and Data Analysis, University of Kansas, 1425 Jayhawk Blvd, Watson Library, 470, Lawrence, KS, US, 66045}},
  issn = {1750-8592},
  abstract = {Planned missing data designs allow researchers to collect incomplete data from participants by randomly assigning participants to have missing items on a survey (multiform designs) or missing measurement occasions in a longitudinal design (wave missing designs) or by administering an intensive measure to a small subsample of a larger dataset (two-method measurement designs). When these designs are implemented correctly and when missingness is dealt with using a modern approach, the cost of data collection is lowered (sometimes dramatically) and reduced participant burden may result in higher validity as well as lower rates of unplanned missing data. In reviewing these planned missing designs, we briefly describe results of ongoing research on bias and power associated with each. (PsycINFO Database Record (c) 2014 APA, all rights reserved). (journal abstract)},
  journal = {Child Development Perspectives},
  keywords = {Experimental Design,Experimentation,intentionally incomplete data,Longitudinal Studies,missing by design,multiform design,planned missing data,Statistical Data,three- form design,two-method measurement,wave missing},
  number = {4}
}

@article{Liu2012,
  title = {Combining Quasi and Empirical Likelihoods in Generalized Linear Models with Missing Responses.},
  author = {Liu, Tianqing and Yuan, Xiaohui},
  year = {2012},
  month = oct,
  volume = {111},
  pages = {39--58},
  publisher = {{Elsevier Science}},
  address = {{Liu, Tianqing, School of Mathematics, Jilin University, Jilin Province, Changchun, China, 130012}},
  issn = {0047-259X},
  abstract = {By only specifying the conditional mean and variance functions of the response variable given covariates, the quasi-likelihood can produce valid semiparametric inference for regression parameter in generalized linear models (GLMs). However, in many studies, auxiliary information is available as moment restrictions of the marginal distribution of the response variable and covariates. We propose the combined quasi and empirical likelihood (CQEL) to incorporate such auxiliary information to improve the efficiency of parameter estimation of the quasi-likelihood in GLMs with missing responses. We show that, when assuming responses are missing at random (MAR), the CQEL estimator achieves better efficiency than the maximum quasi-likelihood (MQL) estimator due to utilization of the auxiliary information. When there is no auxiliary information, we show that the CQEL estimator of the mean response is more efficient than the existing imputation estimators. Based on the asymptotic property of the CQEL estimator, we also develop Wilks' type tests and corresponding confidence regions for the regression parameter and mean response. The merits of the CQEL are further illustrated through simulation studies. (PsycINFO Database Record (c) 2012 APA, all rights reserved). (journal abstract)},
  journal = {Journal of Multivariate Analysis},
  keywords = {Inference,linear models,Linear Regression,Mean,mean responses,missing responses,regression parameters,semi parametric inferences}
}

@article{Liu2013,
  title = {Empirical and Weighted Conditional Likelihoods for Matched Case-Control Studies with Missing Covariates.},
  author = {Liu, Tianqing and Yuan, Xiaohui and Li, Zhaohai and Li, Yuanzhang},
  year = {2013},
  month = aug,
  volume = {119},
  pages = {185--199},
  publisher = {{Elsevier Science}},
  address = {{Li, Yuanzhang}},
  issn = {0047-259X},
  abstract = {In clinical and epidemiological studies, matched case-control designs have been used extensively to investigate the relationships between disease/response and exposure/ covariate. Due to the retrospective nature of the study, some covariates may not be observed for all study subjects and missing covariate information may create bias and reduce the efficiency of the parameter estimates. We explore the use of profile empirical likelihood (EL) to cope with this situation by combining unbiased estimating equations when the number of estimating equations is greater than the number of unknown parameters. For high dimensional covariates, we propose a weighted conditional likelihood (WCL) method to solve the computational problem of the profile EL method. The proposed EL and WCL methods can achieve semiparametric efficiency if the probability of missingness is correctly specified. Based on the EL and WCL functions, we also develop Wilks' type tests and corresponding confidence regions for the model parameters. A simulation study is conducted to assess the performance of the proposed methods in terms of robustness and efficiency. (PsycINFO Database Record (c) 2013 APA, all rights reserved). (journal abstract)},
  journal = {Journal of Multivariate Analysis},
  keywords = {empirical methods,Empirical Methods,Maximum Likelihood,missing covariates,weighted conditional likelihoods}
}

@article{Lu2011,
  title = {Bayesian Inference for Growth Mixture Models with Latent Class Dependent Missing Data.},
  author = {Lu, Zhenqiu Laura and Zhang, Zhiyong and Lubke, Gitta},
  year = {2011},
  month = jul,
  volume = {46},
  pages = {567--597},
  publisher = {{Taylor \& Francis}},
  address = {{Lu, Zhenqiu Laura, University of Notre Dame, Department of Psychology, 118 Hagger Hall, Notre Dame, IN, US, 46556}},
  issn = {0027-3171},
  abstract = {Growth mixture models (GMMs) with nonignorable missing data have drawn increasing attention in research communities but have not been fully studied. The goal of this article is to propose and to evaluate a Bayesian method to estimate the GMMs with latent class dependent missing data. An extended GMM is first pre- sented in which class probabilities depend on some observed explanatory variables and data missingness depends on both the explanatory variables and a latent class variable. A full Bayesian method is then proposed to estimate the model. Through the data augmentation method, conditional posterior distributions for all model parameters and missing data are obtained. A Gibbs sampling procedure is then used to generate Markov chains of model parameters for statistical inference. The application of the model and the method is first demonstrated through the analysis of mathematical ability growth data from the National Longitudinal Survey of Youth 1997 (Bureau of Labor Statistics, U.S. Department of Labor, 1997). A simulation study considering 3 main factors (the sample size, the class probability, and the missing data mechanism) is then conducted and the results show that the proposed Bayesian estimation approach performs very well under the studied conditions. Finally, some implications of this study, including the misspecified missingness mechanism, the sample size, the sensitivity of the model, the number of latent classes, the model comparison, and the future directions of the approach, are discussed. (PsycINFO Database Record (c) 2012 APA, all rights reserved). (journal abstract)},
  journal = {Multivariate Behavioral Research},
  keywords = {Bayesian inference,growth mixture models,Inference,latent class,missing data,Models,Statistical Data,Statistical Probability},
  number = {4}
}

@article{ludtke_multiple_2017,
  title = {Multiple Imputation of Missing Data in Multilevel Designs: {{A}} Comparison of Different Strategies.},
  shorttitle = {Multiple Imputation of Missing Data in Multilevel Designs},
  author = {L{\"u}dtke, Oliver and Robitzsch, Alexander and Grund, Simon},
  year = {2017},
  volume = {22},
  pages = {141--165},
  issn = {1939-1463, 1082-989X},
  doi = {10.1037/met0000096},
  abstract = {Multiple imputation is a widely recommended means of addressing the problem of missing data in psychological research. An often-neglected requirement of this approach is that the imputation model used to generate the imputed values must be at least as general as the analysis model. For multilevel designs in which lower level units (e.g., students) are nested within higher level units (e.g., classrooms), this means that the multilevel structure must be taken into account in the imputation model. In the present article, we compare different strategies for multiply imputing incomplete multilevel data using mathematical derivations and computer simulations. We show that ignoring the multilevel structure in the imputation may lead to substantial negative bias in estimates of intraclass correlations as well as biased estimates of regression coefficients in multilevel models. We also demonstrate that an ad hoc strategy that includes dummy indicators in the imputation model to represent the multilevel structure may be problematic under certain conditions (e.g., small groups, low intraclass correlations). Imputation based on a multivariate linear mixed effects model was the only strategy to produce valid inferences under most of the conditions investigated in the simulation study. Data from an educational psychology research project are also used to illustrate the impact of the various multiple imputation strategies.},
  file = {/Users/tub00573/Zotero/storage/BL383DHS/Lüdtke et al. - 2017 - Multiple imputation of missing data in multilevel .pdf},
  journal = {Psychological Methods},
  language = {English},
  number = {1}
}

@article{Lunneborg2001,
  title = {Random Assignment of Available Cases: Bootstrap Standard Errors and Confidence Intervals.},
  author = {Lunneborg, C E},
  year = {2001},
  month = dec,
  volume = {6},
  pages = {402--12},
  issn = {1082-989X},
  doi = {<a href="javascript:__doLinkPostBack('','ss~~DI\%20\%2210.1037\%2F1082-989X.6.4.402\%22\%7C\%7Csl~~rl','');" title="Search for 10.1037/1082-989X.6.4.402" id="link10.10371082-989X.6.4.402">10.1037/1082-989X.6.4.402</a>},
  abstract = {A frequently used experimental design in psychological research randomly divides a set of available cases, a local population, between 2 treatments and then applies an independent-samples t test to either test a hypothesis about or estimate a confidence interval (CI) for the population mean difference in treatment response. C. S. Reichardt and H. F. Gollob (1999) established that the t test can be conservative for this design-yielding hypothesis test P values that are too large or CIs that are too wide for the relevant local population. This article develops a less conservative approach to local population inference, one based on the logic of B. Efron's (1979) nonparametric bootstrap. The resulting randomization bootstrap is then compared with an established approach to local population inference, that based on randomization or permutation tests. Finally, the importance of local population inference is established by reference to the distinction between statistical and scientific inference.},
  journal = {Psychological methods},
  keywords = {Confidence Intervals,Data Interpretation,Experimental,Experimental: statistics \& numerical d,Humans,Models,Psychology,Psychometrics,Randomized Controlled Trials as Topic,Randomized Controlled Trials as Topic: statistics,Statistical},
  language = {English},
  number = {4},
  pmid = {11778680}
}

@article{Mojirsheibani2007,
  title = {On Nonparametric Classification with Missing Covariates.},
  author = {Mojirsheibani, Majid and Montazeri, Zahra},
  year = {2007},
  month = may,
  volume = {98},
  pages = {1051--1071},
  publisher = {{Elsevier Science}},
  address = {{Mojirsheibani, Majid, Carleton University, Ottawa, ON, Canada, K1S 5B6}},
  issn = {0047-259X},
  abstract = {General procedures are proposed for nonparametric classification in the presence of missing covariates. Both kernel-based imputation as well as Horvitz-Thompson-type inverse weighting approaches are employed to handle the presence of missing covariates. In the case of imputation, it is a certain regression function which is being imputed (and not the missing values). Using the theory of empirical processes, the performance of the resulting classifiers is assessed by obtaining exponential bounds on the deviations of their conditional errors from that of the Bayes classifier. These bounds, in conjunction with the Borel-Cantelli lemma, immediately provide various strong consistency results. (PsycINFO Database Record (c) 2012 APA, all rights reserved). (journal abstract)},
  journal = {Journal of Multivariate Analysis},
  keywords = {Analysis of Covariance,Horvitz-Thompson-type inverse weighting approaches,kernel based imputation,missing covariates,nonparametric classification,Nonparametric Statistical Tests,Statistical Regression,Statistical Weighting},
  number = {5}
}

@article{Muller2014,
  title = {Testing for Additivity in Partially Linear Regression with Possibly Missing Responses.},
  author = {M{\"u}ller, Ursula U and Schick, Anton and Wefelmeyer, Wolfgang},
  year = {2014},
  month = jul,
  volume = {128},
  pages = {51--61},
  publisher = {{Elsevier Science}},
  address = {{M{\"u}ller, Ursula U., Department of Statistics, Texas A\&M University, College Station, TX, US, 77843-3143}},
  issn = {0047-259X},
  abstract = {We consider a partially linear regression model with multivariate covariates and with responses that are allowed to be missing at random. This covers the usual settings with fully observed data and the nonparametric regression model as special cases. We first develop a test for additivity of the nonparametric part in the complete data model. The test statistic is based on the difference between two empirical estimators that estimate the errors in two ways: the first uses a local polynomial smoother for the nonparametric part; the second estimates the additive components by a marginal integration estimator derived from the local polynomial smoother. We present a uniform stochastic expansion of the empirical estimator based on the marginal integration estimator, and we derive the asymptotic distribution of the test statistic. The transfer principle of Koul et al. (2012) then allows a direct adaptation of the results to the case when responses are missing at random. We examine the performance of the tests in a small simulation study. (PsycINFO Database Record (c) 2014 APA, all rights reserved). (journal abstract)},
  journal = {Journal of Multivariate Analysis},
  keywords = {additivity multivariate covariates,Hypothesis Testing,Linear Regression,marginal integration estimator,missing responses,Multivariate Analysis,partially linear regression,Statistical Estimation,statistical testing,Stochastic Modeling,uniform stochastic expansion}
}

@book{Muthen,
  ids = {muthen\_mplus\_1998},
  title = {Mplus User's Guide},
  author = {Muth{\'e}n, L K and Muth{\'e}n, B O},
  year = {2017},
  edition = {Eighth},
  publisher = {{Muth{\'e}n \& Muth{\'e}n}},
  address = {{Los Angeles, CA}}
}

@article{Muthen2011,
  title = {Growth Modeling with Nonignorable Dropout: Alternative Analyses of the {{STAR}}*{{D}} Antidepressant Trial.},
  author = {Muth{\'e}n, Bengt and Asparouhov, Tihomir and Hunter, Aimee M and Leuchter, Andrew F},
  year = {2011},
  month = mar,
  volume = {16},
  pages = {17--33},
  issn = {1939-1463},
  doi = {10.1037/a0022634},
  abstract = {This article uses a general latent variable framework to study a series of models for nonignorable missingness due to dropout. Nonignorable missing data modeling acknowledges that missingness may depend not only on covariates and observed outcomes at previous time points as with the standard missing at random assumption, but also on latent variables such as values that would have been observed (missing outcomes), developmental trends (growth factors), and qualitatively different types of development (latent trajectory classes). These alternative predictors of missing data can be explored in a general latent variable framework with the Mplus program. A flexible new model uses an extended pattern-mixture approach where missingness is a function of latent dropout classes in combination with growth mixture modeling. A new selection model not only allows an influence of the outcomes on missingness but allows this influence to vary across classes. Model selection is discussed. The missing data models are applied to longitudinal data from the Sequenced Treatment Alternatives to Relieve Depression (STAR*D) study, the largest antidepressant clinical trial in the United States to date. Despite the importance of this trial, STAR*D growth model analyses using nonignorable missing data techniques have not been explored until now. The STAR*D data are shown to feature distinct trajectory classes, including a low class corresponding to substantial improvement in depression, a minority class with a U-shaped curve corresponding to transient improvement, and a high class corresponding to no improvement. The analyses provide a new way to assess drug efficiency in the presence of dropout.},
  journal = {Psychological methods},
  keywords = {Adolescent,Adult,Aged,Antidepressive Agents,Antidepressive Agents: therapeutic use,Data Interpretation,Depressive Disorder,Humans,Likelihood Functions,Major,Major: drug therapy,Middle Aged,Models,Patient Dropouts,Randomized Controlled Trials as Topic,Randomized Controlled Trials as Topic: methods,Randomized Controlled Trials as Topic: standards,Statistical,Young Adult},
  language = {English},
  number = {1},
  pmid = {21381817}
}

@article{noble_missing_2012,
  title = {Missing Data in Trial-Based Cost-Effectiveness Analysis: {{The}} Current State of Play},
  shorttitle = {Missing Data in Trial-Based Cost-Effectiveness Analysis},
  author = {Noble, Sian Marie and Hollingworth, William and Tilling, Kate},
  year = {2012},
  month = feb,
  volume = {21},
  pages = {187--200},
  issn = {10579230},
  doi = {10.1002/hec.1693},
  journal = {Health Economics},
  language = {English},
  number = {2}
}

@article{Peng2008,
  title = {Comparison of Two Approaches for Handling Missing Covariates in Logistic Regression.},
  author = {Peng, Chao-Ying Joanne and Zhu, Jin},
  year = {2008},
  month = feb,
  volume = {68},
  pages = {58--77},
  publisher = {{Sage Publications}},
  address = {{Peng, Chao-Ying Joanne, Department of Counseling and Educational Psychology, School of Education, Indiana University, Room 4050, 201 N. Rose Ave., Bloomington, IN, US, 47405-1006}},
  issn = {0013-1644},
  abstract = {For the past 25 years, methodological advances have been made in missing data treatment. Most published work has focused on missing data in dependent variables under various conditions. The present study seeks to fill the void by comparing two approaches for handling missing data in categorical covariates in logistic regression: the expectation-maximization (EM) method of weights and multiple imputation (MI). Sample data are drawn randomly from a population with known characteristics. Missing data on covariates are simulated under two conditions: missing completely at random and missing at random with different missing rates. A logistic regression model was fit to each sample using either the EM or MI approach. The performance of these two approaches is compared on four criteria: bias, efficiency, coverage, and rejection rate. Results generally favored MI over EM. Practical issues such as implementation, inclusion of continuous covariates, and interactions between covariates are discussed. (PsycINFO Database Record (c) 2012 APA, all rights reserved). (journal abstract)},
  journal = {Educational and Psychological Measurement},
  keywords = {Analysis of Covariance,expectation maximization method,Expectations,handling missing covariates,logistic regression,Logistic Regression,multiple imputation,Statistics},
  number = {1}
}

@article{Perez-Gonzalez2010,
  title = {Nonparametric Variance Function Estimation with Missing Data.},
  author = {{P{\'e}rez-Gonz{\'a}lez}, A and {Vilar-Fern{\'a}ndez}, J M and {Gonz{\'a}lez-Manteiga}, W},
  year = {2010},
  month = may,
  volume = {101},
  pages = {1123--1142},
  publisher = {{Elsevier Science}},
  address = {{P{\'e}rez-Gonz{\'a}lez, A., Department of Statistics and Operations Research, University of Vigo, Faculty of Business Sciences, Campus South, 32004, Ourense, Spain}},
  issn = {0047-259X},
  abstract = {In this paper, a fixed design regression model where the errors follow a strictly stationary process is considered. In this model the conditional mean function and the conditional variance function are unknown curves. Correlated errors when observations are missing in the response variable are assumed. Four nonparametric estimators of the conditional variance function based on local polynomial fitting are proposed. Expressions of the asymptotic bias and variance of these estimators are obtained. A simulation study illustrates the behavior of the proposed estimators. (PsycINFO Database Record (c) 2012 APA, all rights reserved). (journal abstract)},
  journal = {Journal of Multivariate Analysis},
  keywords = {errors,Errors,Estimation,function estimation,missing data,Multivariate Analysis,nonparametric variance,regression models,Statistical Data,Statistical Regression},
  number = {5}
}

@article{peugh_missing_2004,
  title = {Missing Data in Educational Research: {{A}} Review of Reporting Practices and Suggestions for Improvement},
  shorttitle = {Missing Data in Educational Research},
  author = {Peugh, James L. and Enders, Craig K.},
  year = {2004},
  month = dec,
  volume = {74},
  pages = {525--556},
  issn = {0034-6543, 1935-1046},
  doi = {10.3102/00346543074004525},
  file = {/Users/tub00573/Zotero/storage/ZFALXLZE/Peugh and Enders - 2004 - Missing Data in Educational Research A Review of .pdf},
  journal = {Review of Educational Research},
  language = {English},
  number = {4}
}

@article{Raaijmakers1999,
  title = {Effectiveness of Different Missing Data Treatments in Surveys with {{Likert}}-Type Data: {{Introducing}} the Relative Mean Substitution Approach.},
  author = {Raaijmakers, Quinten A W},
  year = {1999},
  month = oct,
  volume = {59},
  pages = {725--748},
  publisher = {{Sage Publications}},
  address = {{US}},
  issn = {0013-1644},
  abstract = {Introduces a new approach to the substitution of missing values in surveys with Likert-type scales: relative mean substitution. The effectiveness of this method is demonstrated in comparison with 3 other commonly used methods for dealing with missing values, making use of actual field data from a national survey of 3,220 12\textendash{}24 yr olds in the Netherlands. The emphasis is on 2 aspects of global effectiveness: (1) the accuracy in estimating various parameters at the same time and (2) the accuracy in estimating, for Likert-type scales with different psychometric characteristics, these various parameters under different conditions, such as different numbers of respondents (1,674; 400; and 100) and different distributions of missing values (2 random and 3 nonrandom situations). The results indicate that this new relative mean substitution approach globally produced the most accurate estimates, mainly because of the more accurate estimation of the variances and the sensitivity to items with deviating means, provided that the Likert-type scales are sufficiently homogeneous. The SPSS for Windows setup for computing relative mean is appended. (PsycINFO Database Record (c) 2012 APA, all rights reserved)},
  journal = {Educational and Psychological Measurement},
  keywords = {12–24 yr olds,estimation of missing data in survey research with,Likert Scales,Psychosocial Development DI - 10.1177/00131649921,relative mean substitution approach,Statistical Data,Statistical Estimation,Surveys},
  number = {5}
}

@article{radloff_ces-d_1977,
  title = {The {{CES}}-{{D}} Scale: {{A}} Self-Report Depression Scale for Research in the General Population},
  shorttitle = {The Ces-d Scale},
  author = {Radloff, Lenore Sawyer},
  year = {1977},
  month = jun,
  volume = {1},
  pages = {385--401},
  issn = {0146-6216, 1552-3497},
  doi = {10.1177/014662167700100306},
  file = {/Users/tub00573/Zotero/storage/6TXLLRKP/Radloff - 1977 - The CES-D Scale A Self-Report Depression Scale fo.pdf},
  journal = {Applied Psychological Measurement},
  language = {English},
  number = {3}
}

@article{Ramoni2001,
  title = {Robust Learning with Missing Data},
  author = {Ramoni, Marco and Sebastiani, Paola},
  year = {2001},
  month = nov,
  volume = {45},
  pages = {147--170},
  publisher = {{Kluwer Academic Publishers}},
  issn = {1573-0565},
  journal = {Machine Learning},
  language = {English},
  number = {2}
}

@article{Raykov2005,
  title = {Analysis of Longitudinal Studies with Missing Data Using Covariance Structure Modeling with Full-Information Maximum Likelihood.},
  author = {Raykov, Tenko},
  year = {2005},
  volume = {12},
  pages = {493--505},
  publisher = {{Lawrence Erlbaum}},
  address = {{Raykov, Tenko, Department of Psychology, Fordham University, Bronx, NY, US, 10458}},
  issn = {1070-5511},
  abstract = {A didactic discussion of covariance structure modeling in longitudinal studies with missing data is presented. Use of the full-information maximum likelihood method is considered for model fitting, parameter estimation, and hypothesis testing purposes, particularly when interested in patterns of temporal change as well as its covariates and predictors. The approach is illustrated with an application of the popular level-and-shape model to data from a cognitive intervention study of elderly adults. (PsycINFO Database Record (c) 2012 APA, all rights reserved). (journal abstract)},
  journal = {Structural Equation Modeling},
  keywords = {Aging,Analysis of Covariance,covariance structure modeling,elderly adults,full information maximum likelihood,longitudinal studies,Longitudinal Studies,Maximum Likelihood,missing data,Statistical Analysis DI - 10.1207/s15328007sem120,temporal change},
  number = {3}
}

@article{Raykov2011,
  title = {On Testability of Missing Data Mechanisms in Incomplete Data Sets.},
  author = {Raykov, Tenko},
  year = {2011},
  month = jul,
  volume = {18},
  pages = {419--429},
  publisher = {{Taylor \& Francis}},
  address = {{Raykov, Tenko, Michigan State University, 443A Erickson Hall, East Lansing, MI, US, 48824}},
  issn = {1070-5511},
  abstract = {This article is concerned with the question of whether the missing data mechanism routinely referred to as missing completely at random (MCAR) is statistically examinable via a test for lack of distributional differences between groups with observed and missing data, and related consequences. A discussion is initially provided, from a formal logic standpoint, of the distinction between necessary conditions and sufficient conditions. This distinction is used to argue then that testing for lack of these group distributional differences is not a test for MCAR, and an example is given. The view is next presented that the desirability of MCAR has been frequently overrated in empirical research. The article is finalized with a reference to principled, likelihood-based methods for analyzing incomplete data sets in social and behavioral research. (PsycINFO Database Record (c) 2012 APA, all rights reserved). (journal abstract)},
  journal = {Structural Equation Modeling},
  keywords = {incomplete data,missing completely at random,missing data,missing data mechanism,statistical analysis,Statistical Analysis,Statistical Data DI - 10.1080/10705511.2011.58239},
  number = {3}
}

@article{Raykov2012,
  title = {Examining the Missing Completely at Random Mechanism in Incomplete Data Sets: {{A}} Multiple Testing Approach.},
  author = {Raykov, Tenko and Lichtenberg, Peter A and Paulson, Daniel},
  year = {2012},
  month = jul,
  volume = {19},
  pages = {399--408},
  publisher = {{Taylor \& Francis}},
  address = {{Raykov, Tenko, Measurement and Quantitative Methods, Michigan State University, 443A Erickson Hall, East Lansing, MI, US, 48824}},
  issn = {1070-5511},
  abstract = {A multiple testing procedure for examining implications of the missing completely at random (MCAR) mechanism in incomplete data sets is discussed. The approach uses the false discovery rate concept and is concerned with testing group differences on a set of variables. The method can be used for ascertaining violations of MCAR and disproving this mechanism in empirical behavioral and social research. The procedure can also be employed when locating violations of MCAR in observed measures is of interest. The outlined approach is illustrated with data from a cognitive intervention study. (PsycINFO Database Record (c) 2012 APA, all rights reserved). (journal abstract)},
  journal = {Structural Equation Modeling},
  keywords = {missing completely at random,multiple testing approaches,structural equation modeling,Structural Equation Modeling,Testing DI - 10.1080/10705511.2012.687660},
  number = {3}
}

@article{Raykov2014,
  title = {Identifying Useful Auxiliary Variables for Incomplete Data Analyses: {{A}} Note on a Group Difference Examination Approach.},
  author = {Raykov, Tenko and Marcoulides, George A},
  year = {2014},
  month = jun,
  volume = {74},
  pages = {537--550},
  publisher = {{Sage Publications}},
  address = {{Raykov, Tenko, Measurement and Quantitative Methods, Michigan State University, 443A Erickson Hall, East Lansing, MI, US, 48824}},
  issn = {0013-1644},
  abstract = {This research note contributes to the discussion of methods that can be used to identify useful auxiliary variables for analyses of incomplete data sets. A latent variable approach is discussed, which is helpful in finding auxiliary variables with the property that if included in subsequent maximum likelihood analyses they may enhance considerably the plausibility of the underlying assumption of data missing at random. The auxiliary variables can also be considered for inclusion alternatively in imputation models for following multiple imputation analyses. The approach can be particularly helpful in empirical settings where violations of missing at random are suspected, and is illustrated with data from an aging research study. (PsycINFO Database Record (c) 2014 APA, all rights reserved). (journal abstract)},
  journal = {Educational and Psychological Measurement},
  keywords = {auxiliary variables,confidence interval,Data Collection,incomplete data set,maximum likelihood,Maximum Likelihood,missing at random,Statistical Variables DI - 10.1177/00131644135113},
  number = {3}
}

@article{ruscio_determining_2012,
  title = {Determining the Number of Factors to Retain in an Exploratory Factor Analysis Using Comparison Data of Known Factorial Structure.},
  author = {Ruscio, John and Roche, Brendan},
  year = {2012},
  month = jun,
  volume = {24},
  pages = {282--292},
  issn = {1939-134X, 1040-3590},
  doi = {10.1037/a0025697},
  file = {/Users/tub00573/Zotero/storage/UX2CA9EK/Ruscio and Roche - 2012 - Determining the number of factors to retain in an .pdf},
  journal = {Psychological Assessment},
  language = {English},
  number = {2}
}

@article{Savalei2005,
  title = {A Statistically Justified Pairwise {{ML}} Method for Incomplete Nonnormal Data: {{A}} Comparison with Direct {{ML}} and Pairwise {{ADF}}.},
  author = {Savalei, Victoria and Bentler, Peter M},
  year = {2005},
  month = apr,
  volume = {12},
  pages = {183--214},
  publisher = {{Lawrence Erlbaum}},
  address = {{Bentler, Peter M., Department of Psychology, University of California, 1285 Franz Hall, Box 951563, Los Angeles, CA, US, 90095-1563}},
  issn = {1070-5511},
  abstract = {This article proposes a new approach to the statistical analysis of pairwise-present covariance structure data. The estimator is based on maximizing the complete data likelihood function, and the associated test statistic and standard errors are corrected for misspecification using Satorra-Bentler corrections. A Monte Carlo study was conducted to compare the proposed method (pairwise maximum likelihood [ML]) to 2 other methods for dealing with incomplete nonnormal data: direct ML estimation with the Yuan-Bentler corrections for nonnormality (direct ML) and the asymptotically distribution free (ADF) method applied to available cases (pairwise ADF). Data were generated from a 4-factor model with 4 indicators per factor; sample size varied from 200 to 5,000; data were either missing completely at random (MCAR) or missing at random (MAR); and the proportion of missingness was either 15\% or 30\%. Measures of relative performance included model fit, relative accuracy in parameter estimates and their standard errors, and efficiency of parameter estimates. The results generally favored direct ML over either of the pairwise methods, except at N= 5,000, when ADF outperformed both ML methods with MAR data. The inferior performance of the 2 pairwise methods was primarily due to inflated test statistics. Among the unexpected findings was that ADF did better at estimating factor covariances in all conditions, and that MCAR data presented more problems for all methods than did MAR data, in terms of convergence, performance of test statistics, and relative accuracy of parameter estimates. (PsycINFO Database Record (c) 2012 APA, all rights reserved). (journal abstract)},
  journal = {Structural Equation Modeling},
  keywords = {Analysis of Covariance,asymptotically distribution free method,data missing completely at random,Maximum Likelihood,pairwise maximum likelihood method,pairwise-present covariance structure data,Satorra-Bentler corrections,Statistical Analysis,Statistical Estimation DI - 10.1207/s15328007sem1},
  number = {2}
}

@article{Savalei2008,
  title = {Is the {{ML}} Chi-Square Ever Robust to Nonnormality? {{A}} Cautionary Note with Missing Data.},
  author = {Savalei, Victoria},
  year = {2008},
  month = jan,
  volume = {15},
  pages = {1--22},
  publisher = {{Taylor \& Francis}},
  address = {{Savalei, Victoria, Department of Psychology, University of British Columbia, 2136 West Mall, Vancouver, BC, Canada, V6T 1Z4}},
  issn = {1070-5511},
  abstract = {Normal theory maximum likelihood (ML) is by far the most popular estimation and testing method used in structural equation modeling (SEM), and it is the default in most SEM programs. Even though this approach assumes multivariate normality of the data, its use can be justified on the grounds that it is fairly robust to the violations of the distributional assumptions under some conditions. In support of this claim, a large literature exists outlining conditions under which the ML chi-square retains its asymptotic distribution even under nonnormality. The most important of these conditions is specifying a model in which the exogenous variables presumed to be uncorrelated (e.g., factors and errors in a confirmatory factor analysis model) are also statistically independent. The goal of this article is to point out that these conditions were developed for complete data, and in fact no longer ensure robustness when the data are both nonnormal and incomplete. This lack of robustness is illustrated both mathematically and empirically. Violation becomes more severe when the data are highly nonnormal and when a higher proportion of data is missing. It is concluded that if the proportion of missing data is greater than about 10\%, robustness of the ML chi-square with incomplete nonnormal data cannot be counted on, even if the necessary assumptions such as independence are made. Other approaches to model testing are to be preferred in this case. (PsycINFO Database Record (c) 2012 APA, all rights reserved). (journal abstract)},
  journal = {Structural Equation Modeling},
  keywords = {Chi Square Test,chi-square,estimation method,maximum likelihood,Maximum Likelihood,missing data,Statistical Analysis,Statistical Data,Statistical Estimation,structural equation modeling,Structural Equation Modeling,testing method},
  number = {1}
}

@article{Savalei2009,
  title = {A Two-Stage Approach to Missing Data: {{Theory}} and Application to Auxiliary Variables.},
  author = {Savalei, Victoria and Bentler, Peter M},
  year = {2009},
  month = jul,
  volume = {16},
  pages = {477--497},
  publisher = {{Taylor \& Francis}},
  address = {{Savalei, Victoria, Department of Psychology,University of British Columbia, 2136 West Mall, Vancouver, BC, Canada, V6T 1Z4}},
  issn = {1070-5511},
  abstract = {[Correction Notice: An erratum for this article was reported in Vol 17(4) of Structural Equation Modeling (see record [rid]2010-21580-011[/rid]). In the original article, there was an error in Equation 5. The corrected Equation 5 is given in the erratum.] A well-known ad-hoc approach to conducting structural equation modeling with missing data is to obtain a saturated maximum likelihood (ML) estimate of the population covariance matrix and then to use this estimate in the complete data ML fitting function to obtain parameter estimates. This 2-stage (TS) approach is appealing because it minimizes a familiar function while being only marginally less efficient than the full information ML (FIML) approach. Additional advantages of the TS approach include that it allows for easy incorporation of auxiliary variables and that it is more stable in smaller samples. The main disadvantage is that the standard errors and test statistics provided by the complete data routine will not be correct. Empirical approaches to finding the right corrections for the TS approach have failed to provide unequivocal solutions. In this article, correct standard errors and test statistics for the TS approach with missing completely at random and missing at random normally distributed data are developed and studied. The new TS approach performs well in all conditions, is only marginally less efficient than the FIML approach (and is sometimes more efficient), and has good coverage. Additionally, the residual-based TS statistic outperforms the FIML test statistic in smaller samples. The TS method is thus a viable alternative to FIML, especially in small samples, and its further study is encouraged. (PsycINFO Database Record (c) 2012 APA, all rights reserved). (journal abstract)},
  journal = {Structural Equation Modeling},
  keywords = {application,auxiliary variables,Error of Measurement,maximum likelihood,Maximum Likelihood,missing data,standard errors,Statistics,structural equation modeling,Structural Equation Modeling,test statistics,theory,two stage approach},
  number = {3}
}

@article{Savalei2010,
  title = {'{{A}} Two-Stage Approach to Missing Data: {{Theory}} and Application to Auxiliary Variables'': {{Erratum}}.},
  author = {Savalei, Victoria and Bentler, Peter M},
  year = {2010},
  month = oct,
  volume = {17},
  pages = {714},
  publisher = {{Taylor \& Francis}},
  address = {{United Kingdom}},
  issn = {1070-5511},
  abstract = {Reports an error in "A two-stage approach to missing data: Theory and application to auxiliary variables" by Victoria Savalei and Peter M. Bentler (Structural Equation Modeling, 2009[Jul], Vol 16[3], 477-497). In the original article, there was an error in Equation 5. The corrected Equation 5 is given in the erratum. (The following abstract of the original article appeared in record [rid]2010-12086-003[/rid]). A well-known ad-hoc approach to conducting structural equation modeling with missing data is to obtain a saturated maximum likelihood (ML) estimate of the population covariance matrix and then to use this estimate in the complete data ML fitting function to obtain parameter estimates. This 2-stage (TS) approach is appealing because it minimizes a familiar function while being only marginally less efficient than the full information ML (FIML) approach. Additional advantages of the TS approach include that it allows for easy incorporation of auxiliary variables and that it is more stable in smaller samples. The main disadvantage is that the standard errors and test statistics provided by the complete data routine will not be correct. Empirical approaches to finding the right corrections for the TS approach have failed to provide unequivocal solutions. In this article, correct standard errors and test statistics for the TS approach with missing completely at random and missing at random normally distributed data are developed and studied. The new TS approach performs well in all conditions, is only marginally less efficient than the FIML approach (and is sometimes more efficient), and has good coverage. Additionally, the residual-based TS statistic outperforms the FIML test statistic in smaller samples. The TS method is thus a viable alternative to FIML, especially in small samples, and its further study is encouraged. (PsycINFO Database Record (c) 2012 APA, all rights reserved)},
  journal = {Structural Equation Modeling},
  keywords = {application,auxiliary variables,Error of Measurement,maximum likelihood,Maximum Likelihood,missing data,standard errors,Statistics,structural equation modeling,Structural Equation Modeling,test statistics,theory,two stage approach},
  number = {4}
}

@article{Savalei2012,
  title = {On Obtaining Estimates of the Fraction of Missing Information from Full Information Maximum Likelihood.},
  author = {Savalei, Victoria and Rhemtulla, Mijke},
  year = {2012},
  month = jul,
  volume = {19},
  pages = {477--494},
  publisher = {{Taylor \& Francis}},
  address = {{Savalei, Victoria, Department of Psychology, University of British Columbia, 2136 West Mall, Vancouver, BC, Canada, V6T 1Z4}},
  issn = {1070-5511},
  abstract = {Fraction of missing information {$\lambda$}j is a useful measure of the impact of missing data on the quality of estimation of a particular parameter. This measure can be computed for all parameters in the model, and it communicates the relative loss of efficiency in the estimation of a particular parameter due to missing data. It has been recommended that researchers working with incomplete data sets routinely report this measure, as it is more informative than percent missing data (Bodner, 2008; Schafer, 1997). However, traditional estimates of {$\lambda$}j require the implementation of multiple imputation (MI). Many researchers prefer to fit structural equation models using full information maximum likelihood rather than MI. This article demonstrates how to obtain an estimate of {$\lambda$}j using maximum likelihood estimation routines only and argues that this estimate is superior to the estimate obtained via MI when the number of imputations is small. Interpretation of {$\lambda$}j is also addressed. (PsycINFO Database Record (c) 2012 APA, all rights reserved). (journal abstract)},
  journal = {Structural Equation Modeling},
  keywords = {estimation,Estimation,full information,Information,maximum likelihood,Maximum Likelihood,missing information,structural equation modeling,Structural Equation Modeling},
  number = {3}
}

@article{schafer_missing_2002,
  title = {Missing Data: {{Our}} View of the State of the Art.},
  shorttitle = {Missing Data},
  author = {Schafer, Joseph L. and Graham, John W.},
  year = {2002},
  volume = {7},
  pages = {147--177},
  issn = {1939-1463, 1082-989X},
  doi = {10.1037/1082-989X.7.2.147},
  file = {/Users/tub00573/Zotero/storage/KFSNAZAQ/Schafer and Graham - 2002 - Missing data Our view of the state of the art..pdf},
  journal = {Psychological Methods},
  language = {English},
  number = {2}
}

@article{Schafer1998,
  title = {Multiple Imputation for Multivariate Missing-Data Problems: {{A}} Data Analyst's Perspective.},
  author = {Schafer, Joseph L and Olsen, Maren K},
  year = {1998},
  volume = {33},
  pages = {545--571},
  publisher = {{Lawrence Erlbaum}},
  address = {{US}},
  issn = {0027-3171},
  abstract = {Analyses of multivariate data are frequently hampered by missing values. Until recently, the only missing-data methods available to most data analysts have been relatively ad hoc practices such as listwise deletion. Recent dramatic advances in theoretical and computational statistics, however, have produced a new generation of flexible procedures with a sound statistical basis. These procedures involve multiple imputation (D. B. Rubin, 1987), a simulation technique that replaces each missing datum with a set of m {$>$} 1 plausible values. The m versions of the complete data are analyzed by standard complete-data methods, and the results are combined using simple rules to yield estimates, standard errors, and p-values that formally incorporate missing-data uncertainty. New computational algorithms and software described in a recent book (J. L. Schafer, 1997) allow us to create proper multiple imputations in complex multivariate settings. This article reviews the key ideas of multiple imputation, discusses the software programs currently available, and demonstrates their use on data from the Adolescent Alcohol Prevention Trial (W. B. Hansen and J. W. Graham, 1991). The authors examine the possible effects of a grade 7 intervention on reported alcohol use in grade 9. (PsycINFO Database Record (c) 2012 APA, all rights reserved)},
  journal = {Multivariate Behavioral Research},
  keywords = {7th grade participants in Adolescent Alcohol Preve,Drug Abuse Prevention DI - 10.1207/s15327906mbr33,multiple imputation for multivariate missing data,Multivariate Analysis,Simulation,Statistical Data,Statistical Estimation},
  number = {4},
  series = {Innovative Methods for Prevention Research}
}

@article{Schlomer2010,
  title = {Best Practices for Missing Data Management in Counseling Psychology.},
  author = {Schlomer, Gabriel L. and Bauman, Sheri and Card, Noel A.},
  year = {2010},
  volume = {57},
  pages = {1--10},
  abstract = {This article urges counseling psychology researchers to recognize and report how missing data are handled, because consumers of research cannot accurately interpret findings without knowing the amount and pattern of missing data or the strategies that were used to handle those data. Patterns of missing data are reviewed, and some of the common strategies for dealing with them are described. The authors provide an illustration in which data were simulated and evaluate 3 methods of handling missing data: mean substitution, multiple imputation, and full information maximum likelihood. Results suggest that mean substitution is a poor method for handling missing data, whereas both multiple imputation and full information maximum likelihood are recommended alternatives to this approach. The authors suggest that researchers fully consider and report the amount and pattern of missing data and the strategy for handling those data in counseling psychology research and that editors advise researchers of this expectation.},
  journal = {Journal of Counseling Psychology},
  number = {1}
}

@article{Shadish1998,
  title = {A Method for Exploring the Effects of Attrition in Randomized Experiments with Dichotomous Outcomes.},
  author = {Shadish, William R. and Hu, Xiangen and Glaser, Renita R. and Kownacki, Richard and Wong, Seok},
  year = {1998},
  volume = {3},
  pages = {3--22},
  abstract = {Attrition from conditions in randomized experiments is common. Yet it is difficult to assess the possible effects of attrition because the outcome status of the dropouts is usually unknown. This article develops methods to assess those effects in studies with dichotomous outcomes, illustrating the methods with randomized experiments in drug abuse treatment, smoking cessation treatment, and alcoholism treatment. The methods include computing the lowest and highest possible effect sizes that could have been observed, enumerating the percent of possible study outcomes below a given threshold, estimating the probability that an outcome beyond any given threshold would be observed if all participants were measured, and constructing attrition analysis plots showing the effects of attrition under varied assumptions. For the kind of study to which they apply, these methods should replace the treatment of missing participants as failures in an "intent-to-treat" analysis. A user-friendly personal computer program is available to implement all of these analyses.},
  journal = {Psychological Methods},
  number = {1}
}

@article{shin_maximum_2017,
  title = {Maximum Likelihood versus Multiple Imputation for Missing Data in Small Longitudinal Samples with Nonnormality.},
  author = {Shin, Tacksoo and Davison, Mark L. and Long, Jeffrey D.},
  year = {2017},
  month = sep,
  volume = {22},
  pages = {426--449},
  issn = {1939-1463, 1082-989X},
  doi = {10.1037/met0000094},
  abstract = {The study examined the performance of maximum likelihood (ML) and multiple imputation (MI) procedures for missing data in longitudinal research when fitting latent growth models. A Monte Carlo simulation study was conducted with conditions of small sample size, intermittent missing data, and nonnormality. The results indicated that ML tended to display slightly smaller degrees of bias than MI across missing completely at random (MCAR) and missing at random (MAR) conditions. Although specification of prior information in the MI imputation-posterior (I-P) phase influenced the performance of MI, especially with nonnormal small samples and missing not at random (MNAR), the impact of this tight specification was not dramatic. Several corrected ML test statistics showed proper rejections rates across research designs, whereas posterior predictive p values for MI methods were more likely to be influenced by distribution shape and yielded higher rejection rates in MCAR and MAR than in MNAR. In conclusion, ML appears to be preferable to MI in research conditions with small missing samples and multivariate nonnormality whether or not strong prior information for the I-P phase of MI analysis is available.},
  file = {/Users/tub00573/Zotero/storage/YPVKIKUT/Shin et al. - 2017 - Maximum likelihood versus multiple imputation for .pdf},
  journal = {Psychological Methods},
  language = {English},
  number = {3}
}

@article{Shin2009,
  title = {Effects of Missing Data Methods in Structural Equation Modeling with Nonnormal Longitudinal Data.},
  author = {Shin, Tacksoo and Davison, Mark L and Long, Jeffrey D},
  year = {2009},
  month = jan,
  volume = {16},
  pages = {70--98},
  publisher = {{Taylor \& Francis}},
  address = {{Shin, Tacksoo, Item Bank Department, Korea Institute for Curriculum and Evaluation, 142 Gahoe-ro, Jongno-gu, Seoul, Korea, 110 230}},
  issn = {1070-5511},
  abstract = {The purpose of this study is to investigate the effects of missing data techniques in longitudinal studies under diverse conditions. A Monte Carlo simulation examined the performance of 3 missing data methods in latent growth modeling: listwise deletion (LD), maximum likelihood estimation using the expectation and maximization algorithm with a nonnormality correction (robust ML), and the pairwise asymptotically distribution-free method (pairwise ADF). The effects of 3 independent variables (sample size, missing data mechanism, and distribution shape) were investigated on convergence rate, parameter and standard error estimation, and model fit. The results favored robust ML over LD and pairwise ADF in almost all respects. The exceptions included convergence rates under the most severe nonnormality in the missing not at random (MNAR) condition and recovery of standard error estimates across sample sizes. The results also indicate that nonnormality, small sample size, MNAR, and multicollinearity might adversely affect convergence rate and the validity of statistical inferences concerning parameter estimates and model fit statistics. (PsycINFO Database Record (c) 2012 APA, all rights reserved). (journal abstract)},
  journal = {Structural Equation Modeling},
  keywords = {algorithms,Algorithms,longitudinal data,Longitudinal Studies,missing data,simulation,Simulation,Statistical Data,structural equation modeling,Structural Equation Modeling DI - 10.1080/1070551},
  number = {1}
}

@article{Shutoh2011,
  title = {An Asymptotic Approximation for {{EPMC}} in Linear Discriminant Analysis Based on Two-Step Monotone Missing Samples.},
  author = {Shutoh, Nobumichi and Hyodo, Masashi and Seo, Takashi},
  year = {2011},
  month = feb,
  volume = {102},
  pages = {252--263},
  publisher = {{Elsevier Science}},
  address = {{Shutoh, Nobumichi, Department of Mathematical Information Science, Graduate School of Science, Tokyo University of Science, 1-3, Kagurazaka, Shinjuku-ku, Tokyo, Japan, 162-8601}},
  issn = {0047-259X},
  abstract = {In this paper, we consider the expected probabilities of misclassification (EPMC) in the linear discriminant function (LDF) based on two-step monotone missing samples and derive an asymptotic approximation for the EPMC with an explicit form for the considered LDF. For this purpose, we also provide some results of the expectations for the inverted Wishart matrices in this paper. Finally, we conduct the Monte Carlo simulation for evaluating our result. (PsycINFO Database Record (c) 2012 APA, all rights reserved). (journal abstract)},
  journal = {Journal of Multivariate Analysis},
  keywords = {expected probabilities of misclassification,linear discriminant analysis,monotone missing samples,Monte Carlo simulation,Probability,Simulation,statistics,Statistics DI - 10.1016/j.jmva.2010.09.002},
  number = {2}
}

@article{Sijtsma2003,
  title = {Investigation and Treatment of Missing Item Scores in Test and Questionnaire Data.},
  author = {Sijtsma, Klaas and {van der Ark}, L Andries},
  year = {2003},
  volume = {38},
  pages = {505--528},
  publisher = {{Lawrence Erlbaum}},
  address = {{Sijtsma, Klaas, Department of Methodology and Statistics, FSW, Tilburg University, P.O. Box 90153, 5000 LE, Tilburg, Netherlands}},
  issn = {0027-3171},
  abstract = {This article first discusses a statistical test for investigating whether or not the pattern of missing scores in a respondent-by-item data matrix is random. Since this is an asymptotic test, we investigate whether it is useful in small but realistic sample sizes. Then, we discuss two known simple imputation methods, person mean (PM) and two-way (TW) imputation, and we propose two new imputation methods, response-function (RF) and mean response-function (MRF) imputation. These methods are based on few assumptions about the data structure. An empirical data example with simulated missing item scores shows that the new method RF was superior to the methods PM, TW, and MRF in recovering from incomplete data several statistical properties of the original complete data. Methods TW and RF are useful both when item score missingness is ignorable and nonignorable. (PsycINFO Database Record (c) 2012 APA, all rights reserved)},
  journal = {Multivariate Behavioral Research},
  keywords = {Factor Analysis,imputation,Mean,mean response-function,missing item scores,person mean,questionnaire data,Questionnaires,random data,response-function,Sample Size,sample sizes,Statistical Data,statistical test,Statistical Tests,Test Items DI - 10.1207/s15327906mbr3804_4,Test Scores,two-way imputation},
  number = {4}
}

@article{Silvia2014,
  title = {Planned Missing-Data Designs in Experience-Sampling Research: {{Monte Carlo}} Simulations of Efficient Designs for Assessing within-Person Constructs.},
  author = {Silvia, Paul J and Kwapil, Thomas R and Walsh, Molly A and {Myin-Germeys}, Inez},
  year = {2014},
  month = mar,
  volume = {46},
  pages = {41--54},
  issn = {1554-3528},
  doi = {10.3758/s13428-013-0353-y},
  abstract = {Experience-sampling research involves trade-offs between the number of questions asked per signal, the number of signals per day, and the number of days. By combining planned missing-data designs and multilevel latent variable modeling, we show how to reduce the items per signal without reducing the number of items. After illustrating different designs using real data, we present two Monte Carlo studies that explored the performance of planned missing-data designs across different within-person and between-person sample sizes and across different patterns of response rates. The missing-data designs yielded unbiased parameter estimates but slightly higher standard errors. With realistic sample sizes, even designs with extensive missingness performed well, so these methods are promising additions to an experience-sampler's toolbox.},
  journal = {Behavior research methods},
  keywords = {Behavioral Research,Behavioral Research: methods,Data Interpretation,Humans,Likelihood Functions,Monte Carlo Method,Research Design,Sample Size,Statistical},
  language = {English},
  number = {1},
  pmid = {23709167}
}

@article{Sinharay2001,
  title = {The Use of Multiple Imputation for the Analysis of Missing Data.},
  author = {Sinharay, S and Stern, H S and Russell, D},
  year = {2001},
  month = dec,
  volume = {6},
  pages = {317--29},
  issn = {1082-989X},
  doi = {<a href="http://dx.doi.org.libproxy.temple.edu/10.1037/1082-989X.6.4.317" target="_blank" id="linkhttp:dx.doi.org10.10371082-989X.6.4.317" title="http://dx.doi.org.libproxy.temple.edu/10.1037/1082-989X.6.4.317" data-title="http://dx.doi.org.libproxy.temple.edu/10.1037/1082-989X.6.4.317">http://dx.doi.org.libproxy.temple.edu/10.1037/1082-989X.6.4.317</a>},
  abstract = {This article provides a comprehensive review of multiple imputation (MI), a technique for analyzing data sets with missing values. Formally, MI is the process of replacing each missing data point with a set of m {$>$} 1 plausible values to generate m complete data sets. These complete data sets are then analyzed by standard statistical software, and the results combined, to give parameter estimates and standard errors that take into account the uncertainty due to the missing data values. This article introduces the idea behind MI, discusses the advantages of MI over existing techniques for addressing missing data, describes how to do MI for real problems, reviews the software available to implement MI, and discusses the results of a simulation study aimed at finding out how assumptions regarding the imputation model affect the parameter estimates provided by MI.},
  journal = {Psychological methods},
  keywords = {Bias (Epidemiology),Data Collection,Data Collection: statistics \& numerical data,Experimental,Experimental: statistics \& numerical d,Humans,Likelihood Functions,Mathematical Computing,Psychological Tests,Psychological Tests: statistics \& numerical data,Psychology,Psychometrics,Software},
  language = {English},
  number = {4},
  pmid = {11778675}
}

@article{Song2003,
  title = {Full Maximum Likelihood Estimation of Polychoric and Polyserial Correlations with Missing Data.},
  author = {Song, Xin-Yuan and Lee, Sik-Yum},
  year = {2003},
  month = jan,
  volume = {38},
  pages = {57--79},
  publisher = {{Lawrence Erlbaum}},
  address = {{Lee, Sik-Yum, Dept of Statistics, Chinese U of Hong Kong, Shatin N. T., Hong Kong, China}},
  issn = {0027-3171},
  abstract = {This article develops a full maximum likelihood method for obtaining joint estimates of variances and correlations among continuous and polytomous variables with incomplete data which are missing at random with an ignorable missing mechanism. The approach for obtaining the maximum likelihood estimate of the covariance matrix is via a simple confirmatory analysis model with a fixed identity loading matrix and a fixed diagonal matrix with small of unique variances. A Monte Carlo Expectation-Maximization (MCEM) algorithm is constructed to obtain the solution, in which the E-step is approximated by observations simulated by the Gibbs sampler. Results from a simulation study and a real example are provided to illustrate the methodology. (PsycINFO Database Record (c) 2012 APA, all rights reserved). (journal abstract)},
  journal = {Multivariate Behavioral Research},
  keywords = {continuous variables,covariance matrix,Estimation,ignorable mechanism,Item Response Theory DI - 10.1207/S15327906MBR380,Maximum Likelihood,maximum likelihood estimation,missing data,polytomous variables,Statistical Data},
  number = {1}
}

@article{Song2006,
  title = {A Maximum Likelihood Approach for Multisample Nonlinear Structural Equation Models with Missing Continuous and Dichotomous Data.},
  author = {Song, Xin-Yuan and Lee, Sik-Yum},
  year = {2006},
  volume = {13},
  pages = {325--351},
  publisher = {{Taylor \& Francis}},
  address = {{Lee, Sik-Yum, Department of Statistics, Chinese University of Hong Kong, Shatin, Hong Kong}},
  issn = {1070-5511},
  abstract = {Structural equation models are widely appreciated in social-psychological research and other behavioral research to model relations between latent constructs and manifest variables and to control for measurement error. Most applications of SEMs are based on fully observed continuous normal data and models with a linear structural equation. However, discrete nonnormal data and missing data are rather common, and sometimes it is necessary to incorporate nonlinear structural equations for assessing the impact of nonlinear terms of the exogenous latent variables to the endogenous latent variables. Moreover, to study the behaviors of different populations, it is necessary to extend from a single sample model to a multisample model. In this article, a maximum likelihood (ML) approach is developed for analyzing a multisample nonlinear structural equation model, in the context of mixed continuous and dichotomous data that involve data that are missing at random. The article demonstrates the newly developed methods for estimation and model comparison by a simulation study, a synthetic data application, and a real application to study latent psychological constructs of job attitude, emotion, and benefit attitude that are related to organizational and management research. (PsycINFO Database Record (c) 2012 APA, all rights reserved). (journal abstract)},
  journal = {Structural Equation Modeling},
  keywords = {Data Collection,dichotomous data,Maximum Likelihood,maximum likelihood approach,missing continuous data,nonlinear structural equation models,Structural Equation Modeling},
  number = {3}
}

@article{Song2008,
  title = {A {{Bayesian}} Approach for Analyzing Hierarchical Data with Missing Outcomes through Structural Equation Models.},
  author = {Song, Xin-Yuan and Lee, Sik-Yum},
  year = {2008},
  month = apr,
  volume = {15},
  pages = {272--300},
  publisher = {{Taylor \& Francis}},
  address = {{Lee, Sik-Yum, Department of Statistics, Chinese University of Hong Kong, Shatin, Hong Kong}},
  issn = {1070-5511},
  abstract = {Structural equation models are widely appreciated in behavioral, social, and psychological research to model relations between latent constructs and manifest variables, and to control for measurement errors. Most applications of structural equation models are based on fully observed data that are independently distributed. However, hierarchical data with a correlated structure are common in behavioral research, and very often, missing data are encountered. In this article, we propose a 2-level structural equation model for analyzing hierarchical data with missing entries, and describe a Bayesian approach for estimation and model comparison. We show how to use WinBUGS software to get the solution conveniently. The proposed methodologies are illustrated through a simulation study, and a real application in relation to organizational and management research concerning the study of the interrelationships of the latent constructs about job satisfaction, job responsibility, and life satisfaction for citizens in 43 countries. (PsycINFO Database Record (c) 2012 APA, all rights reserved). (journal abstract)},
  journal = {Structural Equation Modeling},
  keywords = {Bayesian approach,hierarchical data analysis,missing outcomes,Multivariate Analysis,simulation,Simulation,Statistical Data,Statistical Probability,Structural Equation Modeling,structural equation models,WinBUGS software},
  number = {2}
}

@article{StataCorp2011,
  title = {Stata Statistical Software: {{Release}} 12},
  author = {{StataCorp}},
  year = {2011},
  publisher = {{StataCorp LP}},
  address = {{College Station, TX}}
}

@article{Strauss2001,
  title = {Modeling Relationships between Two Categorical Variables When Data Are Missing: {{Examining}} Consequences of the Missing Data Mechanism in an {{HIV}} Data Set.},
  author = {Strauss, Shiela M and Rindskopf, David M and Falkin, Gregory P},
  year = {2001},
  month = oct,
  volume = {36},
  pages = {471--500},
  publisher = {{Lawrence Erlbaum}},
  address = {{Strauss, Shiela M., National Development \& Research Insts, Inc, 71 West 23rd Street, 8th Floor, New York, NY, US, 10010}},
  issn = {0027-3171},
  abstract = {Notes that analysts evaluating the strengths of relationships between variables in behavioral science research often contend with the problem of missing data. Analyses are typically performed using data for cases that are either complete in all the variables, or assume that the data are missing at random. Often, these approaches yield biased results. Using empirical data from 330 drug dependent female offenders, the current work explores the implications and consequences of using various statistical models to describe the association of 2 variables, 1 ordinal and 1 dichotomous, in which data are incomplete for the dichotomous variable. These models explicitly reflect the missing data mechanism; models that hypothesize nonignorable nonresponse are given particular attention. Both the statistical fit and substantive consequences of these models are examined. This methodological approach to examining nonignorable nonresponse can be applied to many behavioral science data sets containing an ordinal variable. (PsycINFO Database Record (c) 2012 APA, all rights reserved)},
  journal = {Multivariate Behavioral Research},
  keywords = {behavioral science research,Behavioral Sciences,Data Collection,missing data,Statistical Measurement,statistical models,Statistical Variables DI - 10.1207/S15327906MBR36,variables},
  number = {4}
}

@article{Subramanian2011,
  title = {Multiple Imputations and the Missing Censoring Indicator Model.},
  author = {Subramanian, Sundarraman},
  year = {2011},
  month = jan,
  volume = {102},
  pages = {105--117},
  publisher = {{Elsevier Science}},
  address = {{Subramanian, Sundarraman}},
  issn = {0047-259X},
  abstract = {Semiparametric random censorship (SRC) models (Dikta, 1998) provide an attractive framework for estimating survival functions when censoring indicators are fully or partially available. When there are missing censoring indicators (MCIs), the SRC approach employs a model-based estimate of the conditional expectation of the censoring indicator given the observed time, where the model parameters are estimated using only the complete cases. The multiple imputations approach, on the other hand, utilizes this model-based estimate to impute the missing censoring indicators and form several completed data sets. The Kaplan\textendash{}Meier and SRC estimators based on the several completed data sets are averaged to arrive at the multiple imputations Kaplan\textendash{}Meier (MIKM) and the multiple imputations SRC (MISRC) estimators. While the MIKM estimator is asymptotically as efficient as or less efficient than the standard SRC-based estimator that involves no imputations, here we investigate the performance of the MISRC estimator and prove that it attains the benchmark variance set by the SRC-based estimator. We also present numerical results comparing the performances of the estimators under several misspecified models for the above mentioned conditional expectation. (PsycINFO Database Record (c) 2012 APA, all rights reserved). (journal abstract)},
  journal = {Journal of Multivariate Analysis},
  keywords = {missing censoring indicator model,multiple imputations,multivariate analysis,Multivariate Analysis,Parametric Statistical Tests DI - 10.1016/j.jmva.,semiparametric models},
  number = {1}
}

@article{Sun2006,
  title = {Estimation of Multivariate Normal Covariance and Precision Matrices in a Star-Shape Model with Missing Data.},
  author = {Sun, Dongchu and Sun, Xiaoqian},
  year = {2006},
  month = mar,
  volume = {97},
  pages = {698--719},
  publisher = {{Elsevier Science}},
  address = {{Sun, Xiaoqian, Department of Statistics, University of Missouri, Columbia, MO, US, 65211}},
  issn = {0047-259X},
  abstract = {In this paper, we study the problem of estimating the covariance matrix {$\Sigma$} and the precision matrix {$\Omega$} (the inverse of the covariance matrix) in a star-shape model with missing data. By considering a type of Cholesky decomposition of the precision matrix {$\Omega$}=\'{Ψ}{$\Psi$}, where {$\Psi$} is a lower triangular matrix with positive diagonal elements, we get the MLEs of the covariance matrix and precision matrix and prove that both of them are biased. Based on the MLEs, unbiased estimators of the covariance matrix and precision matrix are obtained. A special group G, which is a subgroup of the group consisting all lower triangular matrices, is introduced. By choosing the left invariant Haar measure on G as a prior, we obtain the closed forms of the best equivariant estimates of {$\Omega$} under any of the Stein loss, the entropy loss, and the symmetric loss. Consequently, the MLE of the precision matrix (covariance matrix) is inadmissible under any of the above three loss functions. Some simulation results are given for illustration. (PsycINFO Database Record (c) 2012 APA, all rights reserved). (journal abstract)},
  journal = {Journal of Multivariate Analysis},
  keywords = {Analysis of Covariance,Estimation,Mathematical Modeling,missing data,Multivariate Analysis,multivariate normal covariance,precision matrices,star shape model,Statistical Analysis DI - 10.1016/j.jmva.2005.09.},
  number = {3}
}

@article{Sun2009,
  title = {Model Checking for Partially Linear Models with Missing Responses at Random.},
  author = {Sun, Zhihua and Wang, Qihua and Dai, Pengjie},
  year = {2009},
  month = apr,
  volume = {100},
  pages = {636--651},
  publisher = {{Elsevier Science}},
  address = {{Wang, Qihua, Department of Statistics \& Actuarial Science, University of Hong Kong, Pokfulam Road, Hong Kong, China}},
  issn = {0047-259X},
  abstract = {In this paper, we investigate the model checking problem for a partial linear model while some responses are missing at random. By imputation and marginal inverse probability weighted methods, two completed data sets are constructed. Based on the two completed data sets, we build two empirical process-based tests for examining the adequacy of partial linearity of the model. The asymptotic distributions of the test statistics under the null hypothesis and local alternative hypotheses are obtained respectively. A re-sampling approach is applied to obtain the approximation to the null distributions of the test statistics. Simulation results show that the proposed tests work well and both proposed methods have better finite sample properties compared with the complete case (CC) analysis which discards all the subjects with missing data. (PsycINFO Database Record (c) 2012 APA, all rights reserved). (journal abstract)},
  journal = {Journal of Multivariate Analysis},
  keywords = {inverse probably weighting,Mathematical Modeling,missing responses,model checking,null distributions,Null Hypothesis Testing,partially linear models,probability,Probability,Simulation,Statistical Analysis,Statistical Weighting,statistics},
  number = {4}
}

@article{Timm1999,
  title = {Testing Multivariate Effect Sizes in Multiple-Endpoint Studies.},
  author = {Timm, Neil H},
  year = {1999},
  volume = {34},
  pages = {457--465},
  publisher = {{Lawrence Erlbaum}},
  address = {{US}},
  issn = {0027-3171},
  abstract = {Acommon problem in meta-analysis is to test the equality of p correlated effect sizes for k independent studies in which a treatment is compared to a control group. For this problem, two situations arise in practice: all studies use the same outcome variables or some variables are missing. This article investigates these problems using Hotelling's generalized statistic. An example is used to illustrate the procedure. (PsycINFO Database Record (c) 2012 APA, all rights reserved)},
  journal = {Multivariate Behavioral Research},
  keywords = {Effect Size (Statistical),Meta Analysis,Multivariate Analysis DI - 10.1207/S15327906MBR34,problem in meta-analysis of testing equality of p},
  number = {4}
}

@article{Tong2011,
  title = {Abstract: {{Evaluation}} of Test Statistics for Robust Structural Equation Modeling with Nonnormal Missing Data.},
  author = {Tong, Xin and Zhang, Zhiyong and Yuan, Ke-Hai},
  year = {2011},
  month = nov,
  volume = {46},
  pages = {1016},
  publisher = {{Taylor \& Francis}},
  address = {{Tong, Xin, University of Notre Dame, Department of Psychology, 225 Haggar Hall, Notre Dame, IN, US, 46545}},
  issn = {0027-3171},
  abstract = {Traditional structural equation modeling (SEM) techniques have trouble dealing with incomplete and/or nonnormal data that are often encountered in practice. Yuan and Zhang (2011a) developed a two-stage procedure for SEM to handle nonnormal missing data and proposed four test statistics for overall model evaluation. Although these statistics have been shown to work well with complete data, their performance for incomplete data has not been investigated in the context of robust statistics. Focusing on a linear growth curve model, a systematic simulation study is conducted to evaluate the accuracy of the parameter estimates and the performance of five test statistics including the naive statistic derived from normal distribution based maximum likelihood (ML), the Satorra-Bentler scaled chi-square statistic (RML), the mean- and variance-adjusted chi-square statistic (AML), Yuan-Bentler residual-based test statistic (CRADF), and Yuan-Bentler residual-based F statistic (RF). Data are generated and analyzed in R using the package rsem (Yuan \& Zhang, 2011b). Based on the simulation study, we can observe the following: (a) The traditional normal distribution-based method cannot yield accurate parameter estimates for nonnormal data, whereas the robust method obtains much more accurate model parameter estimates for nonnormal data and performs almost as well as the normal distribution based method for normal distributed data. (b) With the increase of sample size, or the decrease of missing rate or the number of outliers, the parameter estimates are less biased and the empirical distributions of test statistics are closer to their nominal distributions. (c) The ML test statistic does not work well for nonnormal or missing data. (d) For nonnormal complete data, CRADF and RF work relatively better than RML and AML. (e) For missing completely at random (MCAR) missing data, in almost all the cases, RML and AML work better than CRADF and RF. (f) For nonnormal missing at random (MAR) missing data, CRADF and RF work better than AML. (g) The performance of the robust method does not seem to be influenced by the symmetry of outliers. (PsycINFO Database Record (c) 2012 APA, all rights reserved). (journal abstract)},
  journal = {Multivariate Behavioral Research},
  keywords = {missing data,parameter estimation,Statistical Analysis,Statistical Data DI - 10.1080/00273171.2011.63671,Statistical Estimation,structural equation modeling,Structural Equation Modeling,test statistics},
  number = {6}
}

@article{Vallejo2011,
  title = {Comparison of Modern Methods for Analyzing Repeated Measures Data with Missing Values.},
  author = {Vallejo, G and Fern{\'a}ndez, M P and {Livacic-Rojas}, P E and {Tuero-Herrero}, E},
  year = {2011},
  month = nov,
  volume = {46},
  pages = {900--937},
  publisher = {{Taylor \& Francis}},
  address = {{Vallejo, G., University of Oviedo, Department of Psychology, Plaza de Benito Feijoo, s/n, 33003, Oviedo, Spain}},
  issn = {0027-3171},
  abstract = {Missing data are a pervasive problem in many psychological applications in the real world. In this article we study the impact of dropout on the operational characteristics of several approaches that can be easily implemented with commercially available software. These approaches include the covariance pattern model based on an unstructured covariance matrix (CPM-U) and the true covariance matrix (CPM-T), multiple imputation-based generalized estimating equations (MI-GEE), and weighted generalized estimating equations (WGEE). Under the missing at random mechanism, the MI-GEE approach was always robust. The CPM-T and CPM-U methods were also able to control the error rates provided that certain minimum sample size requirements were met, whereas the WGEE was more prone to inflated error rates. In contrast, under the missing not at random mechanism, all evaluated approaches were generally invalid. Our results also indicate that the CPM methods were more powerful than the MI-GEE and WGEE methods and their superiority was often substantial. Furthermore, we note that little or no power was sacrificed by using CPM-U method in place of CPM-T, although both methods have less power in situations where some participants have incomplete data. Some aspects of the CPM-U and MI-GEE methods are illustrated using real data from 2 previously published data sets. The first data set comes from a randomized study of AIDS patients with advanced immune suppression, the second from a cohort of patients with schizotypal personality disorder enrolled in a prevention program for psychosis. (PsycINFO Database Record (c) 2012 APA, all rights reserved). (journal abstract)},
  journal = {Multivariate Behavioral Research},
  keywords = {dropout impacts,Dropouts,missing data,missing values,operational characteristics,repeated measures,Repeated Measures,Statistical Analysis,Statistical Data},
  number = {6}
}

@article{Vallejo2011a,
  title = {Selecting the Best Unbalanced Repeated Measures Model.},
  author = {Vallejo, Guillermo and Fern{\'a}ndez, M Paula and {Livacic-Rojas}, Pablo E and {Tuero-Herrero}, Elli{\'a}n},
  year = {2011},
  month = mar,
  volume = {43},
  pages = {18--36},
  issn = {1554-3528},
  doi = {10.3758/s13428-010-0040-1},
  abstract = {This study examined the performance of selection criteria available in the major statistical packages for both mean model and covariance structure. Unbalanced designs due to missing data involving both a moderate and large number of repeated measurements and varying total sample sizes were investigated. The study also investigated the impact of using different estimation strategies for information criteria, the impact of different adjustments for calculating the criteria, and the impact of different distribution shapes. Overall, we found that the ability of consistent criteria in any of the their examined forms to select the correct model was superior under simple covariance patterns than under complex covariance patterns, and vice versa for the efficient criteria. The simulation studies covered in this paper also revealed that, regardless of method of estimation used, the consistent criteria based on number of subjects were more effective than the consistent criteria based on total number of observations, and vice versa for the efficient criteria. Furthermore, results indicated that, given a dataset with missing values, the efficient criteria were more affected than the consistent criteria by the lack of normality.},
  journal = {Behavior research methods},
  keywords = {Algorithms,Analysis of Variance,Bayes Theorem,Behavioral Sciences,Behavioral Sciences: statistics \& numerical data,Computer Simulation,Data Interpretation,Humans,Likelihood Functions,Longitudinal Studies,Longitudinal Studies: statistics \& numerical data,Models,Reproducibility of Results,Research Design,Sample Size,Statistical},
  language = {English},
  number = {1},
  pmid = {21287107}
}

@article{VanGinkel2014,
  title = {Analysis of Variance of Multiply Imputed Data.},
  author = {{van Ginkel}, Joost R and Kroonenberg, Pieter M},
  year = {2014},
  month = jan,
  volume = {49},
  pages = {78--91},
  publisher = {{Taylor \& Francis}},
  address = {{van Ginkel, Joost R., Leiden University, Wassenaarseweg 52, 2333 AK, Leiden, Netherlands}},
  issn = {0027-3171},
  abstract = {As a procedure for handling missing data, Multiple imputation consists of estimating the missing data multiple times to create several complete versions of an incomplete data set. All these data sets are analyzed by the same statistical procedure, and the results are pooled for interpretation. So far, no explicit rules for pooling F tests of (repeated-measures) analysis of variance have been defined. In this article we outline the appropriate procedure for the results of analysis of variance (ANOVA) for multiply imputed data sets. It involves both reformulation of the ANOVA model as a regression model using effect coding of the predictors and applying already existing combination rules for regression models. The proposed procedure is illustrated using 3 example data sets. The pooled results of these 3 examples provide plausible F and p values. (PsycINFO Database Record (c) 2014 APA, all rights reserved). (journal abstract)},
  journal = {Multivariate Behavioral Research},
  keywords = {analysis of variance,Analysis of Variance,Data Processing,missing data,Multiple imputation,multiply imputed data,Statistical Analysis},
  number = {1}
}

@article{velicer_determining_1976,
  title = {Determining the Number of Components from the Matrix of Partial Correlations},
  author = {Velicer, Wayne F.},
  year = {1976},
  month = sep,
  volume = {41},
  pages = {321--327},
  issn = {0033-3123, 1860-0980},
  doi = {10.1007/BF02293557},
  journal = {Psychometrika},
  language = {English},
  number = {3}
}

@article{Velicer2005,
  title = {A Comparison of Missing-Data Procedures for Arima Time-Series Analysis.},
  author = {Velicer, Wayne F and Colby, Suzanne M},
  year = {2005},
  month = aug,
  volume = {65},
  pages = {596--615},
  publisher = {{Sage Publications}},
  address = {{Velicer, Wayne F., Cancer Prevention Research Center, University of Rhode Island, 2 Chafee Road, Kingston, RI, US, 02881-0808}},
  issn = {0013-1644},
  abstract = {Missing data are a common practical problem for longitudinal designs. Time-series analysis is a longitudinal method that involves a large number of observations on a single unit. Four different missing-data methods (deletion, mean substitution, mean of adjacent observations, and maximum likelihood estimation) were evaluated. Computer-generated time-series data of length 100 were generated for 50 different conditions representing five levels of autocorrelation, two levels of slope, and five levels of proportion of missing data. Methods were compared with respect to the accuracy of estimation for four parameters (level, error variance, degree of autocorrelation, and slope). The choice of method had a major impact on the analysis. The maximum likelihood very accurately estimated all four parameters under all conditions tested. The mean of the series was the least accurate approach. Statistical methods such as the maximum likelihood procedure represent a superior approach to missing data. (PsycINFO Database Record (c) 2012 APA, all rights reserved). (journal abstract)},
  journal = {Educational and Psychological Measurement},
  keywords = {longitudinal designs,Longitudinal Studies,maximum likelihood,Maximum Likelihood,missing data,time series analysis,Time Series DI - 10.1177/0013164404272502},
  number = {4}
}

@article{VonHippel2005,
  title = {How Many Imputations Are Needed? {{A}} Comment on Hershberger and Fisher (2003).},
  author = {{von Hippel}, Paul T},
  year = {2005},
  month = apr,
  volume = {12},
  pages = {334--335},
  publisher = {{Lawrence Erlbaum}},
  address = {{von Hippel, Paul T., Department of Sociology, Ohio State University, 300 Bricker Hall, 190 N. Oval Mall, Columbus, OH, US, 43210}},
  issn = {1070-5511},
  abstract = {Comments on the article by Hershberger and Fisher (see record [rid]2003-08838-009[/rid]). Multiple imputation is an increasingly popular strategy for analyzing data with missing values. In multiple imputation, the analyst creates several different versions of a data set, replacing missing values with plausible random values, or imputations. Recently Hershberger and Fisher argued that several hundred imputations are often required. The established advice, however, is that 2 to 10 imputations suffice under most realistic circumstances. In this note we review evidence for the established advice, and explain why it is unnecessary and sometimes impractical to use hundreds of imputations. The authors asserted that the usual guidance is based exclusively on Monte Carlo simulations. The authors arrived at a different recommendation, but there are some difficulties with their approach. Their analysis does not include the fraction of missing information. This omission implies that the appropriate number of imputations is the same whether the sample is 1 \% or 99\% missing. The authors' analysis uses sampling formulas and is based on the assumption that, for example, "it is desired to determine the number of imputations such that the predicted number of imputations differs by no more than 10\% from its 'true' value." (PsycINFO Database Record (c) 2012 APA, all rights reserved)},
  journal = {Structural Equation Modeling},
  keywords = {Error of Measurement,missing data,multiple random imputation,parameter estimates,single random imputation,standard errors,Statistical Data,Statistical Estimation,structural equation modeling,Structural Equation Modeling DI - 10.1207/s153280},
  number = {2}
}

@article{Wang2007,
  title = {Estimation in Partially Linear Models with Missing Responses at Random.},
  author = {Wang, Qihua and Sun, Zhihua},
  year = {2007},
  month = aug,
  volume = {98},
  pages = {1470--1493},
  publisher = {{Elsevier Science}},
  address = {{Wang, Qihua, Academy of Mathematics and Systems Science, Chinese Academy of Science, Beijing, China, 100080}},
  issn = {0047-259X},
  abstract = {A partially linear model is considered when the responses are missing at random. Imputation, semipara-metric regression surrogate and inverse marginal probability weighted approaches are developed to estimate the regression coefficients and the nonparametric function, respectively. All the proposed estimators for the regression coefficients are shown to be asymptotically normal, and the estimators for the nonparametric function are proved to converge at an optimal rate. A simulation study is conducted to compare the finite sample behavior of the proposed estimators. (PsycINFO Database Record (c) 2012 APA, all rights reserved). (journal abstract)},
  journal = {Journal of Multivariate Analysis},
  keywords = {estimation,linear models,missing responses,Multivariate Analysis,random sampling,Random Sampling,regression coefficients,simulation,Simulation,Statistical Correlation,Statistical Estimation},
  number = {7}
}

@article{Wu2009,
  title = {Exact Inference on Contrasts in Means of Intraclass Correlation Models with Missing Responses.},
  author = {Wu, Mi-Xia and Yu, Kai F and Liu, Aiyi},
  year = {2009},
  month = feb,
  volume = {100},
  pages = {301--308},
  publisher = {{Elsevier Science}},
  address = {{Wu, Mi-Xia, Biometry and Mathematical Statistics Branch, Division of Epidemiology, Statistics and Prevention Research, National Institute of Child Health and Human Development, NIH/DHHS, 6100 Executive Boulevard, Rockville, MD, US, 20852}},
  issn = {0047-259X},
  abstract = {Intraclass correlation models with missing data at random are considered. With a properly reduced model, a general method, which allows repeated observations with missing data in a non-monotone pattern, is proposed to construct exact test statistics and simultaneous confidence intervals for linear contrasts in the means. Simulation results are given to compare exact and asymptotic simultaneous confidence intervals. A real example is provided for the illustration of the proposed method. (PsycINFO Database Record (c) 2012 APA, all rights reserved). (journal abstract)},
  journal = {Journal of Multivariate Analysis},
  keywords = {Analysis of Variance,Confidence Limits (Statistics),contrasts,exact inference,intraclass correlation models,missing responses,Responses,Simulation,Statistics},
  number = {2}
}

@article{xu_sensitivity_2011,
  title = {Sensitivity Analysis of Mixed Models for Incomplete Longitudinal Data},
  author = {Xu, Shu and Blozis, Shelley A.},
  year = {2011},
  month = apr,
  volume = {36},
  pages = {237--256},
  issn = {1076-9986, 1935-1054},
  doi = {10.3102/1076998610375836},
  journal = {Journal of Educational and Behavioral Statistics},
  language = {English},
  number = {2}
}

@article{Xue2009,
  title = {Empirical Likelihood for Linear Models with Missing Responses.},
  author = {Xue, Liugen},
  year = {2009},
  month = aug,
  volume = {100},
  pages = {1353--1366},
  publisher = {{Elsevier Science}},
  address = {{Xue, Liugen, College of Applied Sciences, Beijing University of Technology, Beijing, China, 100124}},
  issn = {0047-259X},
  abstract = {The purpose of this article is to use an empirical likelihood method to study the construction of confidence intervals and regions for the parameters of interest in linear regression models with missing response data. A class of empirical likelihood ratios for the parameters of interest are defined such that any of our class of ratios is asymptotically chi-squared. Our approach is to directly calibrate the empirical log-likelihood ratio, and does not need multiplication by an adjustment factor for the original ratio. Also, a class of estimators for the parameters of interest is constructed, and the asymptotic distributions of the proposed estimators are obtained. Our results can be used directly to construct confidence intervals and regions for the parameters of interest. A simulation study indicates that the proposed methods are comparable in terms of coverage probabilities and average lengths/areas of confidence intervals/regions. An example of a real data set is used for illustrating our methods. (PsycINFO Database Record (c) 2012 APA, all rights reserved). (journal abstract)},
  journal = {Journal of Multivariate Analysis},
  keywords = {asymptotic distributions,confidence intervals,Confidence Limits (Statistics),empirical likelihood method,linear regression,Linear Regression,missing response data,Probability,simulation,Simulation,Statistical Analysis,statistical parameters,Statistics},
  number = {7}
}

@article{Xue2011,
  title = {Empirical Likelihood for Semiparametric Regression Model with Missing Response Data.},
  author = {Xue, Liugen and Xue, Dong},
  year = {2011},
  month = apr,
  volume = {102},
  pages = {723--740},
  publisher = {{Elsevier Science}},
  address = {{Xue, Liugen, College of Applied Sciences, Beijing University of Technology, Beijing, China, 100124}},
  issn = {0047-259X},
  abstract = {A bias-corrected technique for constructing the empirical likelihood ratio is used to study a semiparametric regression model with missing response data. We are interested in inference for the regression coefficients, the baseline function and the response mean. A class of empirical likelihood ratio functions for the parameters of interest is defined so that undersmoothing for estimating the baseline function is avoided. The existing data-driven algorithm is also valid for selecting an optimal bandwidth. Our approach is to directly calibrate the empirical log-likelihood ratio so that the resulting ratio is asymptotically chi-squared. Also, a class of estimators for the parameters of interest is constructed, their asymptotic distributions are obtained, and consistent estimators of asymptotic bias and variance are provided. Our results can be used to construct confidence intervals and bands for the parameters of interest. A simulation study is undertaken to compare the empirical likelihood with the normal approximation-based method in terms of coverage accuracies and average lengths of confidence intervals. An example for an AIDS clinical trial data set is used for illustrating our methods. (PsycINFO Database Record (c) 2012 APA, all rights reserved). (journal abstract)},
  journal = {Journal of Multivariate Analysis},
  keywords = {Mathematical Modeling,missing response data,Parametric Statistical Tests,semiparametric regression model,Statistical Data,Statistical Regression},
  number = {4}
}

@article{yang_treatment_2014,
  title = {Treatment Effects in Randomized Longitudinal Trials with Different Types of Nonignorable Dropout.},
  author = {Yang, Manshu and Maxwell, Scott E.},
  year = {2014},
  volume = {19},
  pages = {188--210},
  issn = {1939-1463, 1082-989X},
  doi = {10.1037/a0033804},
  abstract = {Randomized longitudinal designs are commonly used in psychological and medical studies to investigate the treatment effect of an intervention or an experimental drug. Traditional linear mixed-effects models for randomized longitudinal designs are limited to maximum-likelihood methods that assume data are missing at random (MAR). In practice, because longitudinal data are often likely to be missing not at random (MNAR), the traditional mixed-effects model might lead to biased estimates of treatment effects. In such cases, an alternative approach is to utilize pattern-mixture models. In this article, a Monte Carlo simulation study compares the traditional mixed-effects model and 2 different approaches to patternmixture models (i.e., the differencing-averaging method and the averaging-differencing method) across different missing mechanisms (i.e., MAR, random-coefficient-dependent MNAR, or outcome-dependent MNAR) and different types of treatment-condition-based missingness. Results suggest that the traditional mixed-effects model is well suited for analyzing data with the MAR mechanism whereas the proposed pattern-mixture averaging-differencing model has the best overall performance for analyzing data with the MNAR mechanism. No method was found that could provide unbiased estimates under every missing mechanism, leading to a practical suggestion that researchers need to consider why data are missing and should also consider performing a sensitivity analysis to ascertain the extent to which their results are consistent across various missingness assumptions. Applications of different estimation methods are also illustrated using a real-data example.},
  file = {/Users/tub00573/Zotero/storage/YYQSLTNV/Yang and Maxwell - 2014 - Treatment effects in randomized longitudinal trial.pdf},
  journal = {Psychological Methods},
  language = {English},
  number = {2}
}

@article{Yang2005,
  title = {Assessing Missing Data Assumptions in Longitudinal Studies: An Example Using a Smoking Cessation Trial.},
  author = {Yang, Xiaowei and Shoptaw, Steven},
  year = {2005},
  month = mar,
  volume = {77},
  pages = {213--25},
  issn = {0376-8716},
  abstract = {Due to the chaotic nature of the clinical disorder, longitudinal data analysis in substance abuse research is plagued by missing values. To obtain an unbiased estimation on intervention effects, different longitudinal modeling strategies require various assumptions on the patterns and mechanisms of missing data. By defining missingness as intermittent missingness (occasional omission) and dropout (premature withdrawal), this article demonstrates statistical ways for assessing missing data assumptions using evidence from a clinical trial. Within the framework of multiple imputation, intermittent missing data are imputed first so that dropouts can be isolated and treated specifically. A computational tool called "pattern reduction resampling" is proposed to simplify missing data methods when the number of intra-subject repeated measures is large. To test whether missingness patterns are nondifferential across treatment conditions, a formal testing approach treats indicators of missingness as a special type of repeated measures (e.g., 0: intermittent missing, 1: observed, and 2: dropout missing). After reviewing the idea of ignorability for missing data and of classifying missingness mechanisms into subcategories, the article provides an example for assessing common assumptions on missingness mechanisms and how these assumptions affect model selection for significance testing. A carbon monoxide longitudinal data set in a smoking cessation study is used for illustration.},
  journal = {Drug and alcohol dependence},
  keywords = {Bias (Epidemiology),Carbon Monoxide,Carbon Monoxide: blood,Clinical Trials as Topic,Clinical Trials as Topic: statistics \& numerical d,Computer Graphics,Data Collection,Data Collection: statistics \& numerical data,Data Interpretation,Humans,Longitudinal Studies,Methadone,Methadone: therapeutic use,Models,Nicotine,Nicotine: administration \& dosage,Patient Dropouts,Patient Dropouts: statistics \& numerical data,Recurrence,Recurrence: prevention \& control,Reproducibility of Results,Smoking Cessation,Smoking Cessation: methods,Smoking Cessation: statistics \& numerical data,Statistical},
  number = {3}
}

@article{Yuan2004,
  title = {Mardia's Multivariate Kurtosis with Missing Data.},
  author = {Yuan, Ke-Hai and Lambert, Paul L and Fouladi, Rachel T},
  year = {2004},
  volume = {39},
  pages = {413--437},
  publisher = {{Lawrence Erlbaum}},
  address = {{Yuan, Ke-Hai}},
  issn = {0027-3171},
  abstract = {Mardia's measure of multivariate kurtosis has been implemented in many statistical packages commonly used by social scientists. It provides important information on whether a commonly used multivariate procedure is appropriate for inference. Many statistical packages also have options for missing data. However, there is no procedure for applying Mardia's kurtosis to a data set with missing values. In this article Mardia's kurtosis is extended to a data set with missing values. Based on the complete data counterpart, the behavior of a standardized version of the extended sample kurtosis can be described by the standard normal distribution. Analytical and Monte-Carlo studies imply that the proposed distribution description is as good as its complete data counterpart when missing variables are either missing completely at random or missing at random when observed marginals do not sit in a cluster with a restricted range. Application of this procedure is illustrated with a real data set. (PsycINFO Database Record (c) 2012 APA, all rights reserved). (journal abstract)},
  journal = {Multivariate Behavioral Research},
  keywords = {Analysis of Covariance DI - 10.1207/S15327906MBR3,Mardias measure,Measurement,missing data,Multivariate Analysis,rnultivariate kurtosis,Statistical Data,Statistical Variables},
  number = {3}
}

@article{Yuan2008,
  title = {{{SEM}} with Missing Data and Unknown Population Distributions Using Two-Stage {{ML}}: {{Theory}} and Its Application.},
  author = {Yuan, Ke-Hai and Lu, Laura},
  year = {2008},
  month = oct,
  volume = {43},
  pages = {621--652},
  publisher = {{Taylor \& Francis}},
  address = {{Yuan, Ke-Hai, Department of Psychology, University of Notre Dame, Notre Dame, IN, US, 46556}},
  issn = {0027-3171},
  abstract = {This article provides the theory and application of the 2-stage maximum likelihood (ML) procedure for structural equation modeling (SEM) with missing data. The validity of this procedure does not require the assumption of a normally distributed population. When the population is normally distributed and all missing data are missing at random (MAR), the direct ML procedure is nearly optimal for SEM with missing data. When missing data mechanisms are unknown, including auxiliary variables in the analysis will make the missing data mechanism more likely to be MAR. It is much easier to include auxiliary variables in the 2-stage ML than in the direct ML. Based on most recent developments for missing data with an unknown population distribution, the article first provides the least technical material on why the normal distribution-based ML generates consistent parameter estimates when the missing data mechanism is MAR. The article also provides sufficient conditions for the 2-stage ML to be a valid statistical procedure in the general case. For the application of the 2-stage ML, an SAS IML program is given to perform the first-stage analysis and EQS codes are provided to perform the second-stage analysis. An example with open- and closed-book examination data is used to illustrate the application of the provided programs. One aim is for quantitative graduate students/applied psychometricians to understand the technical details for missing data analysis. Another aim is for applied researchers to use the method properly. (PsycINFO Database Record (c) 2012 APA, all rights reserved). (journal abstract)},
  journal = {Multivariate Behavioral Research},
  keywords = {maximum likelihood,Maximum Likelihood,missing at random,Normal Distribution,parameter estimation,Simulation,structural equation modeling,Structural Equation Modeling},
  number = {4}
}

@article{Yuan2009,
  title = {Identifying Variables Responsible for Data Not Missing at Random.},
  author = {Yuan, Ke-Hai},
  year = {2009},
  month = jun,
  volume = {74},
  pages = {233--256},
  publisher = {{Springer}},
  address = {{Yuan, Ke-Hai, Department of Psychology, University of Notre Dame, Notre Dame, IN, US, 46556}},
  issn = {0033-3123},
  abstract = {When data are not missing at random (NMAR), maximum likelihood (ML) procedure will not generate consistent parameter estimates unless the missing data mechanism is correctly modeled. Understanding NMAR mechanism in a data set would allow one to better use the ML methodology. A survey or questionnaire may contain many items; certain items may be responsible for NMAR values in other items. The paper develops statistical procedures to identify the responsible items. By comparing ML estimates (MLE), statistics are developed to test whether the MLEs are changed when excluding items. The items that cause a significant change of the MLEs are responsible for the NMAR mechanism. Normal distribution is used for obtaining the MLEs; a sandwich-type covariance matrix is used to account for distribution violations. The class of non normal distributions within which the procedure is valid is provided. Both saturated and structural models are considered. Effect sizes are also defined and studied. The results indicate that more missing data in a sample does not necessarily imply more significant test statistics due to smaller effect sizes. Knowing the true population means and covariances or the parameter values in structural equation models may not make things easier either. (PsycINFO Database Record (c) 2012 APA, all rights reserved). (journal abstract)},
  journal = {Psychometrika},
  keywords = {effect size,Effect Size (Statistical),maximum likelihood,Maximum Likelihood,missing data mechanism,not missing at random,parameter bias,Statistics,Structural Equation Modeling,structural equation models},
  number = {2}
}

@article{Yuan2010,
  title = {Combining Conditional and Unconditional Moment Restrictions with Missing Responses.},
  author = {Yuan, Xiaohui and Liu, Tianqing and Lin, Nan and Zhang, Baoxue},
  year = {2010},
  month = nov,
  volume = {101},
  pages = {2420--2433},
  publisher = {{Elsevier Science}},
  address = {{Liu, Tianqing}},
  issn = {0047-259X},
  abstract = {Many statistical models, e.g. regression models, can be viewed as conditional moment restrictions when distributional assumptions on the error term are not assumed. For such models, several estimators that achieve the semiparametric efficiency bound have been proposed. However, in many studies, auxiliary information is available as unconditional moment restrictions. Meanwhile, we also consider the presence of missing responses. We propose the combined empirical likelihood (CEL) estimator to incorporate such auxiliary information to improve the estimation efficiency of the conditional moment restriction models. We show that, when assuming responses are strongly ignorable missing at random, the CEL estimator achieves better efficiency than the previous estimators due to utilization of the auxiliary information. Based on the asymptotic property of the CEL estimator, we also develop Wilks' type tests and corresponding confidence regions for the model parameter and the mean response. Since kernel smoothing is used, the CEL method may have difficulty for problems with high dimensional covariates. In such situations, we propose an instrumental variable-based empirical likelihood (IVEL) method to handle this problem. The merit of the CEL and IVEL are further illustrated through simulation studies. (PsycINFO Database Record (c) 2012 APA, all rights reserved). (journal abstract)},
  journal = {Journal of Multivariate Analysis},
  keywords = {combined empirical likelihood,conditional moment restrictions,Maximum Likelihood,missing responses,multivariate analysis,Multivariate Analysis,unconditional moment restrictions},
  number = {10}
}

@article{Yuan2012,
  title = {Robust Structural Equation Modeling with Missing Data and Auxiliary Variables.},
  author = {Yuan, Ke-Hai and Zhang, Zhiyong},
  year = {2012},
  month = oct,
  volume = {77},
  pages = {803--826},
  publisher = {{Springer}},
  address = {{Yuan, Ke-Hai, Department of Psychology, University of Notre Dame, Notre Dame, IN, US, 46556}},
  issn = {0033-3123},
  abstract = {The paper develops a two-stage robust procedure for structural equation modeling (SEM) and an R package rsem to facilitate the use of the procedure by applied researchers. In the first stage, M-estimates of the saturated mean vector and covariance matrix of all variables are obtained. Those corresponding to the substantive variables are then fitted to the structural model in the second stage. A sandwich-type covariance matrix is used to obtain consistent standard errors (SE) of the structural parameter estimates. Rescaled, adjusted as well as corrected and F-statistics are proposed for overall model evaluation. Using R and EQS, the R package rsem combines the two stages and generates all the test statistics and consistent SEs. Following the robust analysis, multiple model fit indices and standardized solutions are provided in the corresponding output of EQS. An example with open/closed book examination data illustrates the proper use of the package. The method is further applied to the analysis of a data set from the National Longitudinal Survey of Youth 1997 cohort, and results show that the developed procedure not only gives a better endorsement of the substantive models but also yields estimates with uniformly smaller standard errors than the normal-distribution-based maximum likelihood. (PsycINFO Database Record (c) 2012 APA, all rights reserved). (journal abstract)},
  journal = {Psychometrika},
  keywords = {Analysis of Covariance,auxiliary variables,covariance matrix,missing data,Statistical Data,structural equation modeling,Structural Equation Modeling},
  number = {4}
}

@article{Zhang2013,
  title = {Methods for Mediation Analysis with Missing Data.},
  author = {Zhang, Zhiyong and Wang, Lijuan},
  year = {2013},
  month = jan,
  volume = {78},
  pages = {154--184},
  publisher = {{Springer}},
  address = {{Zhang, Zhiyong, University of Notre Dame, Notre Dame, IN, US}},
  issn = {0033-3123},
  abstract = {Despite wide applications of both mediation models and missing data techniques, formal discussion of mediation analysis with missing data is still rare. We introduce and compare four approaches to dealing with missing data in mediation analysis including listwise deletion, pairwise deletion, multiple imputation (MI), and a two-stage maximum likelihood (TS-ML) method. An R package bmem is developed to implement the four methods for mediation analysis with missing data in the structural equation modeling framework, and two real examples are used to illustrate the application of the four methods. The four methods are evaluated and compared under MCAR, MAR, and MNAR missing data mechanisms through simulation studies. Both MI and TS-ML perform well for MCAR and MAR data regardless of the inclusion of auxiliary variables and for AV-MNAR data with auxiliary variables. Although listwise deletion and pairwise deletion have low power and large parameter estimation bias in many studied conditions, they may provide useful information for exploring missing mechanisms. (PsycINFO Database Record (c) 2013 APA, all rights reserved). (journal abstract)},
  journal = {Psychometrika},
  keywords = {Item Analysis (Statistical),listwise deletion,Maximum Likelihood,maximum likelihood method,mediation analysis,Methodology,missing data techniques,multiple imputation,pairwise deletion,parameter estimation bias,Simulation DI - 10.1007/s11336-012-9301-5,simulation studies,Statistical Data,Statistical Estimation},
  number = {1}
}

@article{zhu_automatic_2006,
  title = {Automatic Dimensionality Selection from the Scree Plot via the Use of Profile Likelihood},
  author = {Zhu, Mu and Ghodsi, Ali},
  year = {2006},
  month = nov,
  volume = {51},
  pages = {918--930},
  issn = {01679473},
  doi = {10.1016/j.csda.2005.09.010},
  journal = {Computational Statistics \& Data Analysis},
  language = {English},
  number = {2}
}

@article{Zoppe2001,
  title = {Parameter Estimation under Constraints for Multivariate Normal Distributions with Incomplete Data.},
  author = {Zopp{\'e}, Alice and Buu, Yuh-Pey Anne and Flury, Bernard},
  year = {2001},
  volume = {26},
  pages = {219--232},
  publisher = {{American Educational Research Assn}},
  address = {{Zopp{\'e}, Alice}},
  issn = {1076-9986},
  abstract = {This work presents an application of the EM algorithm to two problems of estimation and testing in a multivariate normal distribution with missing data. The assumptions are that the observations are multivariate normally distributed and that the missing values are missing at random. The two models are tested applying the log-likelihood ratio test; for deriving the maximum likelihood estimates and evaluating the corresponding log-likelihood functions the EM algorithm is used. The problem of different and non-monotone patterns of missing data is solved introducing suitable transformations and partitions of the data matrix. The algorithm is proposed for general constraints on the mean vector; the topic of exchangeability of random vectors is also presented. (PsycINFO Database Record (c) 2012 APA, all rights reserved). (journal abstract)},
  journal = {Journal of Educational and Behavioral Statistics},
  keywords = {Algorithms,EM-algorithm,likelihood,Maximum Likelihood,missing or incomplete data,Multivariate Analysis,multivariate normal distribution,Normal Distribution,parameter estimation,Statistical Estimation DI - 10.3102/1076998602600,testing},
  number = {2}
}


